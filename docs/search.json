[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Psychological Wellbeing, Sleep, and Video Gaming: Analyses of Comprehensive Digital Traces",
    "section": "",
    "text": "This website describes the data simulation, preprocessing, and analysis code for our Stage 1 Registered Report.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Psychological Wellbeing, Sleep, and Video Gaming: Analyses of Comprehensive Digital Traces</span>"
    ]
  },
  {
    "objectID": "0_generateSyntheticData.html",
    "href": "0_generateSyntheticData.html",
    "title": "2  Generate Synthetic Data",
    "section": "",
    "text": "2.1 Preamble\nFirst, set options and load some libraries we’ll need.\nShow code (options)\nknitr::opts_chunk$set(\n  echo = knitr::is_html_output(),\n  warning = FALSE,\n  message = FALSE,\n  output = TRUE\n)\n\nset.seed(8675309)\nShow code (load libraries)\nif (!require(\"pacman\")) install.packages(\"pacman\")\nlibrary(pacman)\n\np_load(\n  tidyverse, jsonlite, qualtRics, sjlabelled, hms, openxlsx, scales\n)\nShow code (custom functions)\n# Function to generate a random time in hh:mm format\nrandomTime &lt;- function(n) {\n  randomHours &lt;- runif(n, 0, 24)\n  randomMinutes &lt;- runif(n, 0, 60)\n  randomTimes &lt;- now() + dhours(randomHours) + dminutes(randomMinutes)\n  format(randomTimes, \"%H:%M\")\n}\n\n# Function to randomly assign 1-3 genres to a game\nassignGenres &lt;- function(genres) {\n  numGenres &lt;- sample(1:3, 1, prob = c(.5, .3, .2))\n  genres &lt;- sample(genres, numGenres, replace = FALSE)\n  paste(genres, collapse = \", \")\n}\n\n# function to sample from a zero-inflated gamma distribution, used for iOS app categories\nsampleTime &lt;- function(n) {\n  ifelse(runif(n) &lt; 0.4, 0, rgamma(n, shape = 3, scale = 2 / 2))\n}\n\n# Sample a single row from df_source based on a matching ID\nsampleRowByID &lt;- function(id, df, nRows) {\n  df |&gt;\n    filter(ID == !!id) |&gt; # Filter rows that match the given ID\n    slice_sample(n = nRows, replace = FALSE) # Randomly sample one row\n}\nThen, import the true data we need, from which we’ll do some bootstrapping.\nShow code (load data)\n# some files are available online\nif (!file.exists(\"data/survey.csv.gz\")) {\n  dir.create(\"data\")\n  datSurvey &lt;- read_csv(\"https://github.com/digital-wellbeing/noa-pilot-ms/raw/main/data/survey.csv.gz\")\n  write_csv(datSurvey, \"data/survey.csv.gz\")\n\n  datNintendo &lt;- read_csv(\"https://github.com/digital-wellbeing/noa-pilot-ms/raw/main/data/telemetry.csv.gz\")\n  write_csv(datNintendo, \"data/telemetry.csv.gz\")\n\n  datDemo &lt;- read_csv(\"https://github.com/digital-wellbeing/noa-pilot-ms/raw/main/data/demographics.csv.gz\")\n  write_csv(datDemo, \"data/demographics.csv.gz\")\n\n  datMeta &lt;- read_csv(\"https://github.com/digital-wellbeing/noa-pilot-ms/raw/main/data/gameMetadata.csv.gz\")\n  write_csv(datMeta, \"data/gameMetadata.csv.gz\")\n} else {\n  datSurvey &lt;- read_csv(\"data/survey.csv.gz\")\n  datNintendo &lt;- read_csv(\"data/telemetry.csv.gz\")\n  datDemo &lt;- read_csv(\"data/demographics.csv.gz\")\n  datMeta &lt;- read_csv(\"data/gameMetadata.csv.gz\")\n}\n\n# other files are only available on onedrive privately (paths specified in .Renviron)\ndatXbox &lt;- read.delim(Sys.getenv(\"xboxDataPath\"))\ndatSteam &lt;- read_csv(Sys.getenv(\"steamDataPath\")) |&gt;\n  filter(played == \"Yes\")\ndatAndroid &lt;- fromJSON(Sys.getenv(\"androidDataPath\"))\n\n# and three are available through the Qualtrics API (internal use only)\n\ndatIntake &lt;- fetch_survey(Sys.getenv(\"QUALTRICS_INTAKE_SURVEY_ID\"), include_display_order = FALSE) |&gt;\n  select(-(StartDate:consent), -(isWilling:RANDOM_ID), -gender_4_TEXT) |&gt;\n  mutate(playProp_7 = \"\") # fix one broken column\n\n# pull panel survey from qualtrics - make sure test responses for the latest\n# published version of the survey have already been generated\n# two steps because we need to mutate without losing labels \ndatPanelRaw &lt;- fetch_survey(Sys.getenv(\"QUALTRICS_PANEL_SURVEY_ID\"), include_display_order = FALSE)\n\ndatPanel &lt;- datPanelRaw |&gt;\n  select(-c(StartDate:UserLanguage), -PID, -wave) |&gt; \n  # test responses for mctq don't work at all so we need to fill these in manually\n  mutate(\n    mctq_2_1 = sample(0:7, n(), replace = TRUE, prob = c(.05, .05, .10, .10, .20, .25, .15, .10)),\n    across(c(mctq_6_6, mctq_6_4, mctq_3_6, mctq_3_4), ~ runif(n(), min = 1, max = 60)),\n    across(c(mctq_3_1, mctq_3_3, mctq_3_5, mctq_6_1, mctq_6_3, mctq_6_5), ~ randomTime(n()))\n  ) |&gt; \n# Reapply the original labels to ensure they are retained\n  copy_labels(datPanelRaw)\n\n# pull diary survey from qualtrics - make sure test responses for the latest\n# published version of the survey have already been generated\ndatDiary &lt;- fetch_survey(Sys.getenv(\"QUALTRICS_DIARY_SURVEY_ID\"), include_display_order = FALSE) |&gt;\n  select(-c(StartDate:UserLanguage), -PID, -wave)\n\nif (!file.exists(\"data-synthetic\")) {\n  dir.create(\"data-synthetic\")\n}\nSet up basic parameters of the data simulation.\nShow code (simulation parameters)\nset.seed(8675309)\nn &lt;- 2000\ndiaryWaves &lt;- 21\npanelWaves &lt;- 6\nstudyStartDate &lt;- as_datetime(\"2024-05-01 00:00:00\")\nstudyDays &lt;- panelWaves * 14\nstudyDates &lt;- ymd(studyStartDate + days(0:studyDays))",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Generate Synthetic Data</span>"
    ]
  },
  {
    "objectID": "0_generateSyntheticData.html#preamble",
    "href": "0_generateSyntheticData.html#preamble",
    "title": "2  Generate Synthetic Data",
    "section": "",
    "text": "Note\n\n\n\nSome files are available publicly online; others are private and only on OneDrive (paths specified in .Renviron); and other are pulled using the Qualtrics API (internal use only).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Generate Synthetic Data</span>"
    ]
  },
  {
    "objectID": "0_generateSyntheticData.html#simulate-participant-sample",
    "href": "0_generateSyntheticData.html#simulate-participant-sample",
    "title": "2  Generate Synthetic Data",
    "section": "2.2 Simulate participant sample",
    "text": "2.2 Simulate participant sample\nFirst we simulate the sample as taken - their age, gender, region, and gameplay tendencies. We bootstrap from existing Nintendo pilot data, but add some demographic details that are not present in the Prolific data. This takes the format of the intake questionnaire on Qualtrics, and therefore needs to import that survey.\nWe also simulate the gameplay behavior of participants - what platforms do they play on, and how frequently do they play on each of them.\n\n\n\n\n\n\nNote\n\n\n\nParticipant platforms don’t match the responses in the platforms_X intake items, as these are generated from Qualtrics test responses. We have a better idea of the platform distribution so we simulate that ourselves.\n\n\n\n2.2.1 Intake\n\n\nShow code (simulate intake)\nsynIntake &lt;- tibble(\n  pid = as.character(1:n),\n  region = rep(c(\"US\", \"UK\"), n / 2)\n) |&gt;\n  # bootstrap each column from the non-NA values in the original data\n  cbind(map_dfc(datIntake, ~ rep(sample(.[!is.na(.)], length(.), replace = TRUE), length.out = n))) |&gt;\n  # for a handful of relevant columns, we override the generate test response\n  # distributions with custom ones\n  mutate(\n    age = ifelse(region == \"US\",\n      sample(18:30, n, replace = TRUE),\n      sample(18:75, n, replace = TRUE)\n    ),\n    sex = sample(datDemo$sexProlific[!is.na(datDemo$sexProlific)],\n      n(),\n      replace = TRUE\n    ),\n    employment = sample(\n      datDemo$employmentStatusProlific[!is.na(datDemo$employmentStatusProlific) &\n        datDemo$employmentStatusProlific != \"DATA_EXPIRED\"],\n      n(),\n      replace = TRUE\n    ),\n    eduLevel = sample(datSurvey$eduLevel[!is.na(datSurvey$eduLevel)], n(), replace = TRUE),\n    ethnicity = sample(datDemo$ethnicity[!is.na(datDemo$ethnicity)], n(), replace = TRUE),\n    height = ifelse(sex == \"Male\",\n      round(rnorm(n(), 69, 3)),\n      round(rnorm(n(), 64, 3))\n    ),\n    weight = ifelse(sex == \"Male\",\n      round(rnorm(n(), 190, 35)),\n      round(rnorm(n(), 160, 35))\n    ),\n    localTimeZone = sample(datDemo$localTimeZone[!is.na(datDemo$localTimeZone)], n(), replace = TRUE)\n  ) |&gt;\n  # convert height into feet and inches\n  mutate(\n    `height#1_1_1` = height %% 12,\n    `height#1_1_2` = height %/% 12,\n    .keep = \"unused\"\n  ) |&gt;\n  # add gaming characteristics\n  mutate(\n    playsSwitch = sample(c(TRUE, FALSE), n(), prob = c(.4, .6), replace = TRUE),\n    playsXbox = sample(c(TRUE, FALSE), n(), prob = c(.5, .5), replace = TRUE),\n    playsSteam = ifelse(region == \"US\",\n      sample(c(TRUE, FALSE), n(), prob = c(.5, .5), replace = TRUE),\n      FALSE\n    ),\n    playsSteam = ifelse(!playsSwitch & !playsXbox & !playsSteam, TRUE, playsSteam), # so that all players play on at least one platform\n\n    # for people who play on a given platform, how likely are they to play on a particular day, using beta distribution\n    dailyNintendoPlayLikelihood = ifelse(playsSwitch, rbeta(n(), 2, 8), 0),\n    dailyXboxPlayLikelihood = ifelse(playsXbox, rbeta(n(), 3, 5), 0),\n    dailySteamPlayLikelihood = ifelse(playsSteam, rbeta(n(), 3, 5), 0),\n    iOSuser = sample(c(TRUE, FALSE), n(), prob = c(.7, .3), replace = TRUE),\n    androidUser = !iOSuser\n  ) |&gt;\n  copy_labels(datIntake)\n\n\n\n\n2.2.2 Play History\nNext, we want to simulate some play behavior. We assume that each player has a fixed likelihood of playing on each platform they use on a given day. If they do play, we assume they will play between 1 and 3 sessions (or in the case of Steam, that they have logged playtime in 1-5 1-hour periods of the day). We simulate those values here.\n\n\nShow code (simulate play history)\nsynPlayHistory &lt;- synIntake |&gt;\n  crossing(day = 1:studyDays) |&gt;\n  mutate(date = studyDates[day]) |&gt;\n  select(pid, day, date, starts_with(c(\"plays\", \"daily\"))) |&gt;\n  rowwise() |&gt;\n  mutate(\n    numSessionsNintendo = ifelse(runif(n()) &lt; dailyNintendoPlayLikelihood,\n      sample(1:3, 1, prob = c(.7, .2, .1)),\n      0\n    ),\n    numSessionsXbox = ifelse(runif(n()) &lt; dailyXboxPlayLikelihood,\n      sample(1:3, 1, prob = c(.7, .2, .1)),\n      0\n    ),\n    numHoursWithSteamPlay = ifelse(runif(n()) &lt; dailySteamPlayLikelihood,\n      sample(1:5, 1, prob = c(.4, .25, .2, .1, .05)),\n      0\n    ),\n  )\n\n\n\n\n2.2.3 Dropout/attrition\nHere, we simulate the properties of participant dropout. We assume that participants have a base rate of missingness at each wave (5% for diary, 10% for panel), and a separate chance each day of dropping out for the rest of the study (1% for the 84 days of the study). We simulate the missingness and dropout for each participant for each day of the study, and use this information later to remove rows from the completed panel and diary surveys.\n\n\nShow code (simulate dropout)\ndropout &lt;- expand.grid(pid = 1:n, day = 1:studyDays) |&gt;\n  # first define the various time components of the study\n  mutate(\n    diaryWave = ifelse(day &lt;= 30, day, NA),\n    week = ceiling(day / 7),\n    panelWave = ifelse((day - 1) %% 14 == 0, (day - 1) %/% 14 + 1, NA) # return 1 on day 1, 2 on day 15, 3 on day 29, etc\n  ) |&gt;\n  arrange(as.integer(pid), day) |&gt;\n  # for simplicity, first we simulate dropout for every day of the study, then only keep the missingness on relevant days\n  mutate(\n    missingDiary = sample(c(TRUE, FALSE), n(), replace = TRUE, prob = c(.05, .5)),\n    missingPanel = sample(c(TRUE, FALSE), n(), replace = TRUE, prob = c(.1, .9)),\n    dropout = sample(c(TRUE, FALSE), n(), replace = TRUE, prob = c(.01, .99))\n  ) |&gt;\n  mutate(\n    missingPanel = ifelse(is.na(panelWave), NA, missingPanel),\n    missingDiary = ifelse(is.na(diaryWave), NA, missingDiary)\n  ) |&gt;\n  group_by(pid) |&gt;\n  mutate(\n    missingPanel = ifelse(cumsum(dropout) &gt; 0, TRUE, missingPanel),\n    missingDiary = ifelse(cumsum(dropout) &gt; 0, TRUE, missingDiary)\n  ) |&gt;\n  # clean up\n  ungroup() |&gt;\n  mutate(pid = as_character(pid))",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Generate Synthetic Data</span>"
    ]
  },
  {
    "objectID": "0_generateSyntheticData.html#simulate-telemetry",
    "href": "0_generateSyntheticData.html#simulate-telemetry",
    "title": "2  Generate Synthetic Data",
    "section": "2.3 Simulate Telemetry",
    "text": "2.3 Simulate Telemetry\nFirst we quickly generate a list of unique genres, which we will later randomly assign to games. In the real study, we will match games on all platforms to these same categories using the IGDB database.\n\n2.3.1 Genres\n\n\nShow code (simulate genres)\n# We pull from the genres present in the Nintendo metadata (which were in turn pulled from IGDB)\nuniqueGenres &lt;- datMeta |&gt;\n  filter(!is.na(genres)) |&gt; # Remove NAs\n  separate_rows(genres, sep = \",\") |&gt; # Split by comma\n  distinct(genres) |&gt; # Get unique genres\n  pull(genres) |&gt;\n  sort()\n\n\n\n\n2.3.2 Nintendo\nNext, we simulate the session-level data based on the play behavior, starting with Nintendo. For each day and session that a participant has played, we bootstrap the title, start time, and duration, from the existing data. For example, Participant 14 played Switch on Day 11, and their play was simulated to include 2 unique sessions. Games, session start times, and session durations are all drawn randomly from the real Nintendo data.\n\n\nShow code (simulate Nintendo data)\nsynNintendo &lt;- synPlayHistory |&gt;\n  filter(numSessionsNintendo &gt; 0) |&gt;\n  mutate(session = list(1:numSessionsNintendo)) |&gt;\n  unnest(session) |&gt;\n  mutate(\n    titleID = sample(datNintendo$titleID, n(), replace = TRUE),\n    sessionStart = date + seconds(runif(n(), 0, 86400)),\n    duration = sample(datNintendo$duration, n(), replace = TRUE),\n    sessionEnd = sessionStart + minutes(as.integer(duration)),\n    genre = replicate(n(), assignGenres(uniqueGenres)),\n  ) |&gt;\n  select(-(playsSwitch:numHoursWithSteamPlay)) |&gt;\n  mutate(platform = \"Nintendo\")\n\nglimpse(synNintendo)\n\n\nRows: 19,565\nColumns: 10\n$ pid          &lt;chr&gt; \"10\", \"10\", \"10\", \"10\", \"100\", \"100\", \"100\", \"100\", \"100\"…\n$ day          &lt;int&gt; 17, 17, 17, 31, 1, 3, 9, 15, 15, 21, 21, 27, 27, 29, 32, …\n$ date         &lt;date&gt; 2024-05-17, 2024-05-17, 2024-05-17, 2024-05-31, 2024-05-…\n$ session      &lt;int&gt; 1, 2, 3, 1, 1, 1, 1, 1, 2, 1, 2, 1, 2, 1, 1, 1, 2, 3, 1, …\n$ titleID      &lt;chr&gt; \"Animal Crossing New Horizons\", \"Splatoon 2\", \"Animal Cro…\n$ sessionStart &lt;dttm&gt; 2024-05-17 02:33:18, 2024-05-17 17:38:18, 2024-05-17 03:…\n$ duration     &lt;dbl&gt; 38.2, 4.3, 77.3, 4.1, 52.9, 32.7, 11.3, 101.3, 74.8, 9.7,…\n$ sessionEnd   &lt;dttm&gt; 2024-05-17 03:11:18, 2024-05-17 17:42:18, 2024-05-17 04:…\n$ genre        &lt;chr&gt; \"Sport, Strategy, MOBA\", \"Puzzle, Racing\", \"MOBA\", \"Visua…\n$ platform     &lt;chr&gt; \"Nintendo\", \"Nintendo\", \"Nintendo\", \"Nintendo\", \"Nintendo…\n\n\n\n\n2.3.3 Xbox\nWe take a similar approach for the Xbox data. However, instead of bootstrapping, we instead randomly pull from a list of an external list of Xbox games. We pull session start times from the Nintendo dataset as these are probably an equally good representation, but simulate a new set of durations as the average Xbox session is likely longer than Nintendo.\n\n\nShow code (simulate Xbox data)\nxboxGames &lt;- read_csv(\"https://github.com/ItsLogic/Xbox-TitleIDs/raw/main/IDs.csv\")[1:300, ]\n\nsynXbox &lt;- synPlayHistory |&gt;\n  filter(numSessionsXbox &gt; 0) |&gt;\n  mutate(session = list(1:numSessionsXbox)) |&gt;\n  unnest(session) |&gt;\n  mutate(\n    titleID = sample(xboxGames$`Game Title`, n(), replace = TRUE),\n    sessionStart = date + seconds(runif(n(), 0, 86400)),\n    duration = round(rgamma(n(), shape = 2, rate = 1) * 60, 2),\n    sessionEnd = sessionStart + minutes(as.integer(duration)),\n    genre = replicate(n(), assignGenres(uniqueGenres))\n  ) |&gt;\n  select(-(playsSwitch:numHoursWithSteamPlay)) |&gt;\n  mutate(platform = \"Xbox\")\n\nglimpse(synXbox)\n\n\nRows: 42,649\nColumns: 10\n$ pid          &lt;chr&gt; \"10\", \"10\", \"10\", \"10\", \"10\", \"10\", \"10\", \"10\", \"10\", \"10…\n$ day          &lt;int&gt; 10, 10, 10, 15, 15, 16, 17, 22, 23, 24, 25, 29, 30, 30, 3…\n$ date         &lt;date&gt; 2024-05-10, 2024-05-10, 2024-05-10, 2024-05-15, 2024-05-…\n$ session      &lt;int&gt; 1, 2, 3, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 2, …\n$ titleID      &lt;chr&gt; \"Forza Street\", \"11-11 Memories Retold\", \"Shadow Fencer T…\n$ sessionStart &lt;dttm&gt; 2024-05-10 10:21:25, 2024-05-10 21:12:30, 2024-05-10 12:…\n$ duration     &lt;dbl&gt; 67.87, 28.36, 93.43, 193.32, 85.92, 62.88, 52.64, 79.32, …\n$ sessionEnd   &lt;dttm&gt; 2024-05-10 11:28:25, 2024-05-10 21:40:30, 2024-05-10 14:…\n$ genre        &lt;chr&gt; \"Music\", \"Hack and slash/Beat 'em up\", \"Real Time Strateg…\n$ platform     &lt;chr&gt; \"Xbox\", \"Xbox\", \"Xbox\", \"Xbox\", \"Xbox\", \"Xbox\", \"Xbox\", \"…\n\n\n\n\n2.3.4 Steam\nNext, we move to Steam data. Here we use an existing sample of Steam data as output by Gameplay.Science (hosted on OneDrive, path specified in .Renviron).\nIn contrast to Xbox and Nintendo data, Steam data is not session-level; rather, it is a total amount of time spent playing each game during the previous hour. We simulate this by looking if the person played that day, simulating a random number of hours between 1-5 that they may have played, and then filling in an amount of time for each hour of play.\nWe also randomly assign genres to each game, as we did for Nintendo and Xbox.\n\n\nShow code (simulate Steam data)\n# note that the code structure of the steam sim is a little different, as it derives from a different process (using LLMs to generate user personas)\nsteam &lt;- read_csv(Sys.getenv(\"steamDataPath\")) |&gt;\n  filter(played == \"Yes\")\n\n# with more realistic numbers of sessions per player, the loop iteration was getting prohibitively slow\n# so we assign a random persona for each observation in synPlayHistory, then suse sampleRowByID() to only sample rows from steam\n# where the ID matches.  This is much faster, with the only downside being that different days may have identical sessions,\n# but I don't see this as a problem for the purposes of the sim (and in fact this might have been happening before anyway?)\nsynSteam &lt;- synPlayHistory |&gt;\n  mutate(persona = sample(unique(steam$ID), n(), replace = TRUE)) |&gt; # assign random persona\n  filter(numHoursWithSteamPlay &gt; 0) |&gt; # for each day where steam play occurs\n  mutate(\n    sampled_row = list(sampleRowByID(persona, steam, numHoursWithSteamPlay)) # sample a certain number of hour-sessions from that persona\n  ) |&gt;\n  unnest(cols = c(sampled_row)) |&gt;\n  # clean up\n  select(pid, day, date, hour = time, everything(), -(playsSwitch:numHoursWithSteamPlay), -ID, -played) |&gt;\n\n  # add some columns to match the format of the other datasets\n  mutate(\n    sessionStart = as.POSIXct(paste(date, hour), format = \"%Y-%m-%d %H\"), \n    sessionEnd = sessionStart+minutes(as.integer(minutes))\n  ) |&gt; \n  arrange(as.integer(pid), day, date, hour) |&gt;\n  mutate(platform = \"Steam\")\n\nglimpse(synSteam)\n\n\nRows: 65,792\nColumns: 12\n$ pid          &lt;chr&gt; \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1…\n$ day          &lt;int&gt; 1, 1, 2, 3, 5, 5, 9, 10, 10, 10, 10, 11, 14, 14, 14, 15, …\n$ date         &lt;date&gt; 2024-05-01, 2024-05-01, 2024-05-02, 2024-05-03, 2024-05-…\n$ hour         &lt;dbl&gt; 1, 16, 0, 1, 1, 2, 2, 0, 1, 2, 3, 13, 1, 2, 3, 3, 6, 12, …\n$ persona      &lt;dbl&gt; 293, 293, 113, 348, 317, 317, 182, 579, 579, 579, 579, 57…\n$ genre        &lt;chr&gt; \"Action,Adventure,Indie\", \"Action,Adventure,Indie\", \"Acti…\n$ minutes      &lt;dbl&gt; 30, 30, 45, 30, 30, 25, 50, 45, 30, 50, 40, 30, 30, 50, 4…\n$ AppID        &lt;dbl&gt; 231160, 2537770, 788820, 433570, 488860, 430170, 1449690,…\n$ Name         &lt;chr&gt; \"The Swapper\", \"Stay Still 2\", \"Lightning War\", \"Side Que…\n$ sessionStart &lt;dttm&gt; 2024-05-01 01:00:00, 2024-05-01 16:00:00, 2024-05-02 00:…\n$ sessionEnd   &lt;dttm&gt; 2024-05-01 01:30:00, 2024-05-01 16:30:00, 2024-05-02 00:…\n$ platform     &lt;chr&gt; \"Steam\", \"Steam\", \"Steam\", \"Steam\", \"Steam\", \"Steam\", \"St…\n\n\n\n\n2.3.5 iOS\niOS data consists of weekly screen time data for the below categories (pre-defined by Apple). We simulate the value of each of these categories for each participant-week using a zero-inflated gamma distribution, then add dropout as before.\n\n\nShow code (simulate iOS data)\nappCategories &lt;- c(\n  \"Entertainment\", \"Social\", \"Information & Reading\", \"Games\", \"Productivity & Finance\", \"Travel\", \"Other\",\n  \"Creativity\", \"Education\", \"Health & Fitness\", \"Shopping & Food\", \"Utilities\"\n)\n\nsyniOS &lt;- expand.grid(\n  pid = synIntake$pid[synIntake$iOSuser],\n  week = 1:(panelWaves * 2),\n  category = appCategories\n) |&gt;\n  mutate(\n    duration = sampleTime(n()),\n    date = studyDates[week * 7 - 6]\n  ) |&gt;\n  pivot_wider(names_from = category, values_from = duration, values_fill = 0) %&gt;%\n  mutate(totalScreentime = rowSums(select(., -c(pid, week, date)))) |&gt;\n  mutate(\n    missing = sample(c(TRUE, FALSE), n(), replace = TRUE, prob = c(.1, .9)),\n    dropout = sample(c(TRUE, FALSE), n(), replace = TRUE, prob = c(.01, .99))\n  ) |&gt;\n  group_by(pid) |&gt;\n  mutate(missing = ifelse(cumsum(dropout) &gt; 0, TRUE, missing)) |&gt;\n  ungroup() |&gt;\n  select(pid, week, date, missing, dropout, everything()) |&gt;\n  mutate(across(-c(pid, week, missing, dropout), ~ if_else(missing | dropout, NA, .))) |&gt;\n  arrange(as.integer(pid), week) |&gt; mutate(platform = \"iOS\")\n\nglimpse(syniOS)\n\n\nRows: 16,836\nColumns: 19\n$ pid                      &lt;fct&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, …\n$ week                     &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1, 2, …\n$ date                     &lt;date&gt; 2024-05-01, 2024-05-08, 2024-05-15, 2024-05-…\n$ missing                  &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FAL…\n$ dropout                  &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FAL…\n$ Entertainment            &lt;dbl&gt; 0.0000000, 5.7292596, 2.4548014, 1.9636654, 1…\n$ Social                   &lt;dbl&gt; 3.873012, 0.000000, 0.000000, 7.768210, 2.192…\n$ `Information & Reading`  &lt;dbl&gt; 2.0640570, 1.0929347, 0.0000000, 0.0000000, 0…\n$ Games                    &lt;dbl&gt; 2.556279, 6.762721, 2.680783, 1.584198, 1.374…\n$ `Productivity & Finance` &lt;dbl&gt; 5.0285683, 0.0000000, 0.0000000, 0.0000000, 0…\n$ Travel                   &lt;dbl&gt; 4.2951315, 4.4039391, 1.9020418, 6.9663217, 2…\n$ Other                    &lt;dbl&gt; 3.105830, 0.000000, 3.684219, 1.378007, 5.816…\n$ Creativity               &lt;dbl&gt; 2.6572140, 3.0750600, 4.2126908, 1.5049544, 0…\n$ Education                &lt;dbl&gt; 3.5425213, 1.0298568, 4.2429778, 1.2054966, 0…\n$ `Health & Fitness`       &lt;dbl&gt; 4.7835503, 2.4794736, 0.0000000, 0.0000000, 1…\n$ `Shopping & Food`        &lt;dbl&gt; 0.0000000, 0.0000000, 5.0112091, 0.0000000, 2…\n$ Utilities                &lt;dbl&gt; 2.8956759, 0.0000000, 0.0000000, 1.1620841, 0…\n$ totalScreentime          &lt;dbl&gt; 34.80184, 24.57324, 24.18872, 23.53294, 17.75…\n$ platform                 &lt;chr&gt; \"iOS\", \"iOS\", \"iOS\", \"iOS\", \"iOS\", \"iOS\", \"iO…\n\n\n\n\n2.3.6 Android\nLast, we simulate android data, bootstrapping from a sample ActivityWatch output (hosted on OneDrive, path specified in .Renviron).\n\n\nShow code (simulate Android data)\n# Extract and normalize the 'events' data - app sessions - which are found in the 'aw-watcher-android-test' bucket\nandroidEvents &lt;- datAndroid$buckets$`aw-watcher-android-test`$events |&gt;\n  as_tibble() |&gt;\n  flatten()\n\nsynAndroid &lt;- expand.grid(\n  pid = synIntake$pid[synIntake$androidUser],\n  day = 1:studyDays\n) |&gt;\n  mutate(\n    numDailyAppSessions = round(rgamma(n(), 10, .5)),\n    date = studyDates[day]\n  ) |&gt; # simulate a random number of app sessions to have taken place that day\n  rowwise() |&gt;\n  mutate(session = list(1:numDailyAppSessions)) |&gt;\n  unnest(session) |&gt;\n  mutate(\n    app = sample(androidEvents$data.app, n(), replace = TRUE), ,\n    sessionStart = sample(ymd_hms(androidEvents$timestamp), n(), replace = TRUE),\n    sessionStart = as.period(as_hms(sessionStart)),\n    duration = sample(androidEvents$duration, n(), replace = TRUE),\n    sessionEnd = sessionStart + minutes(as.integer(duration)),\n  ) |&gt;\n  # for simplicity at the simulation stage, we simply random assign categories to each app, matching the iOS categories\n  # in the full paper, we will map apps to categories using the google play store API\n  group_by(app) |&gt;\n  mutate(category = sample(appCategories, 1, replace = TRUE)) |&gt;\n  ungroup() |&gt;\n  arrange(as.integer(pid), day, sessionStart) |&gt; mutate(platform = \"Android\")\n\nglimpse(synAndroid)\n\n\nRows: 1,001,307\nColumns: 11\n$ pid                 &lt;fct&gt; 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,…\n$ day                 &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ numDailyAppSessions &lt;dbl&gt; 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26…\n$ date                &lt;date&gt; 2024-05-01, 2024-05-01, 2024-05-01, 2024-05-01, 2…\n$ session             &lt;int&gt; 7, 6, 15, 26, 17, 1, 23, 3, 21, 13, 20, 8, 9, 14, …\n$ app                 &lt;chr&gt; \"Kiwi Browser\", \"Samsung Internet\", \"Spotify\", \"Tr…\n$ sessionStart        &lt;Period&gt; 6H 25M 37.1729998588562S, 7H 2M 26.187999963760…\n$ duration            &lt;dbl&gt; 0.085, 1.168, 6.528, 22.051, 27.117, 1.377, 4.638,…\n$ sessionEnd          &lt;Period&gt; 6H 25M 37.1729998588562S, 7H 3M 26.187999963760…\n$ category            &lt;chr&gt; \"Utilities\", \"Entertainment\", \"Travel\", \"Social\", …\n$ platform            &lt;chr&gt; \"Android\", \"Android\", \"Android\", \"Android\", \"Andro…",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Generate Synthetic Data</span>"
    ]
  },
  {
    "objectID": "0_generateSyntheticData.html#simulate-self-report-data-diary-and-panel",
    "href": "0_generateSyntheticData.html#simulate-self-report-data-diary-and-panel",
    "title": "2  Generate Synthetic Data",
    "section": "2.4 Simulate self-report data (diary and panel)",
    "text": "2.4 Simulate self-report data (diary and panel)\nWe now move to the self-report data. For both surveys, the simplest option is to just use Qualtrics’ “generate test response” feature, then pull that data using the Qualtrics API, so that the simulated data accurately mirrors the structure of the data we will later have (if not the distributional properties).\nWe’ll want to add missingness and dropout to both the panel and diary data, which we do by adding a base chance of missingness at every wave, alongside a separate chance at each wave that the participant will drop out for the rest of the study. See above for details.\n\n2.4.1 Panel\n\n\nShow code (simulate panel data)\nsynPanel &lt;- expand.grid(pid = as.character(1:n), wave = 1:panelWaves) |&gt;\n  # add random completion time between 12pm and 12pm the following day\n  mutate(\n    date = studyDates[wave * 14 - 13],\n    surveyCompletionTime = date + seconds(runif(n(), 43200, 129600))\n  ) |&gt;\n  # bootstrap each column from the non-NA values in the original data\n  cbind(map_dfc(datPanel, ~ rep(sample(.[!is.na(.)], length(.), replace = TRUE), length.out = n * panelWaves))) |&gt;\n\n  # Special transformation needs to be done to `psqi_4#1_1_1` and `psqi_4#1_1_2` columns to move values in normal range.\n  mutate(\n    `psqi_4#1_1_1` = rescale(`psqi_4#1_1_1`, to = c(0, 12), na.rm = TRUE),\n    `psqi_4#1_1_2` = rescale(`psqi_4#1_1_2`, to = c(0, 60), na.rm = TRUE)\n  ) |&gt; \n  # certain measures are only administered at certain waves, set these to 0 for\n  # the other waves\n  mutate(across(starts_with(c(\"BFI\", \"trojan\", \"mctq\")), ~ ifelse(wave != 1, NA, .))) |&gt;\n  mutate(across(starts_with(\"gdt\"), ~ ifelse(wave %in% c(2:5), NA, .))) |&gt;\n  mutate(across(starts_with(c(\"psqi\", \"eps\")), ~ ifelse(wave %in% c(1, 3, 5), NA, .))) |&gt;\n  # join with the relevant rows/cols of the missingness df\n  left_join(dropout |&gt; filter(!is.na(panelWave)) |&gt; select(pid, panelWave, missingPanel),\n    by = c(\"pid\", \"wave\" = \"panelWave\")\n  ) |&gt;\n  select(pid, wave, date, missingPanel, everything()) |&gt;\n  # remove data for all missing diary waves\n  mutate(across(-c(pid, wave, missingPanel), ~ if_else(missingPanel, NA, .))) |&gt;\n  arrange(as.numeric(pid), wave) |&gt;\n  copy_labels(datPanel)\n\n\n\n\nClick to view the structure of the panel data\n\n\nglimpse(synPanel)\n\nRows: 12,000\nColumns: 165\n$ pid                     &lt;chr&gt; \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"2\", \"2\", \"2\", \"…\n$ wave                    &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4…\n$ date                    &lt;date&gt; 2024-05-01, 2024-05-15, 2024-05-29, 2024-06-1…\n$ missingPanel            &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, TRUE, TRUE, FALSE,…\n$ surveyCompletionTime    &lt;dttm&gt; 2024-05-02 04:46:30, 2024-05-16 07:26:35, 202…\n$ problematicPlay         &lt;chr&gt; \"Phasellus. Est diam per erat integer wisi nul…\n$ positives               &lt;chr&gt; \"Ultrices per ab massa ac euismod blandit sem …\n$ gdt_1                   &lt;chr&gt; \"Sometimes\", NA, NA, NA, NA, NA, \"Often\", NA, …\n$ gdt_2                   &lt;chr&gt; \"Sometimes\", NA, NA, NA, NA, NA, \"Sometimes\", …\n$ gdt_3                   &lt;chr&gt; \"Never\", NA, NA, NA, NA, NA, \"Often\", NA, NA, …\n$ gdt_4                   &lt;chr&gt; \"Often\", NA, NA, NA, NA, NA, \"Often\", NA, NA, …\n$ mctq_1                  &lt;int&gt; 2, NA, NA, NA, NA, NA, 2, NA, NA, NA, NA, NA, …\n$ mctq_2_1                &lt;int&gt; 6, NA, NA, NA, NA, NA, 2, NA, NA, NA, NA, NA, …\n$ mctq_3_1                &lt;chr&gt; \"05:43\", NA, NA, NA, NA, NA, \"23:47\", NA, NA, …\n$ mctq_3_2                &lt;chr&gt; \"Enim felis curabitur? Molestie eu sagittis ne…\n$ mctq_3_3                &lt;chr&gt; \"14:12\", NA, NA, NA, NA, NA, \"07:25\", NA, NA, …\n$ mctq_3_4                &lt;dbl&gt; 39.20008, NA, NA, NA, NA, NA, 44.62950, NA, NA…\n$ mctq_3_5                &lt;chr&gt; \"13:57\", NA, NA, NA, NA, NA, \"11:58\", NA, NA, …\n$ mctq_3_6                &lt;dbl&gt; 5.796318, NA, NA, NA, NA, NA, 47.058190, NA, N…\n$ mctq_4_1                &lt;chr&gt; \"No\", NA, NA, NA, NA, NA, \"Yes\", NA, NA, NA, N…\n$ mctq_5_1                &lt;chr&gt; \"No\", NA, NA, NA, NA, NA, \"No\", NA, NA, NA, NA…\n$ mctq_6_1                &lt;chr&gt; \"10:33\", NA, NA, NA, NA, NA, \"18:00\", NA, NA, …\n$ mctq_6_2                &lt;chr&gt; \"Sed eleifend proin rutrum. Orci culpa at luct…\n$ mctq_6_3                &lt;chr&gt; \"03:56\", NA, NA, NA, NA, NA, \"01:17\", NA, NA, …\n$ mctq_6_4                &lt;dbl&gt; 13.251418, NA, NA, NA, NA, NA, 56.047642, NA, …\n$ mctq_6_5                &lt;chr&gt; \"02:01\", NA, NA, NA, NA, NA, \"22:03\", NA, NA, …\n$ mctq_6_6                &lt;dbl&gt; 6.658175, NA, NA, NA, NA, NA, 37.259872, NA, N…\n$ mctq_7_1                &lt;chr&gt; \"Yes\", NA, NA, NA, NA, NA, \"No\", NA, NA, NA, N…\n$ mctq_7_2                &lt;chr&gt; \"Yes\", NA, NA, NA, NA, NA, \"Yes\", NA, NA, NA, …\n$ mctq_8_1                &lt;chr&gt; \"Hobbies\", NA, NA, NA, NA, NA, \"Child(ren)/pet…\n$ mctq_9                  &lt;chr&gt; \"Auctor neque per? Quam nonummy leo ligula sed…\n$ `psqi_1#1_1_1`          &lt;dbl&gt; NA, 30320142, NA, 109754050, NA, NA, NA, 14886…\n$ `psqi_1#1_1_2`          &lt;dbl&gt; NA, 543316285, NA, 833081673, NA, NA, NA, 9163…\n$ `psqi_1#2_1`            &lt;chr&gt; NA, \"AM\", NA, \"AM\", NA, NA, NA, \"PM\", NA, \"AM\"…\n$ psqi_2                  &lt;dbl&gt; NA, 546670535, NA, 1772158820, NA, NA, NA, 189…\n$ `psqi_3#1_1_1`          &lt;dbl&gt; NA, 1784034938, NA, 1489034961, NA, NA, NA, 20…\n$ `psqi_3#1_1_2`          &lt;dbl&gt; NA, 1786659833, NA, 924252618, NA, NA, NA, 166…\n$ `psqi_3#2_1`            &lt;chr&gt; NA, \"PM\", NA, \"AM\", NA, NA, NA, \"AM\", NA, \"PM\"…\n$ `psqi_4#1_1_1`          &lt;dbl&gt; NA, 7.591414, NA, 4.088766, NA, NA, NA, 1.3164…\n$ `psqi_4#1_1_2`          &lt;dbl&gt; NA, 41.987484, NA, 44.030600, NA, NA, NA, 52.9…\n$ psqi_5_1                &lt;chr&gt; NA, \"Once or twice a week\", NA, \"Less than onc…\n$ psqi_5_2                &lt;chr&gt; NA, \"Less than once a week\", NA, \"Three or mor…\n$ psqi_5_3                &lt;chr&gt; NA, \"Once or twice a week\", NA, \"Once or twice…\n$ psqi_5_4                &lt;chr&gt; NA, \"Three or more times a week\", NA, \"Once or…\n$ psqi_5_5                &lt;chr&gt; NA, \"Less than once a week\", NA, \"Three or mor…\n$ psqi_5_6                &lt;chr&gt; NA, \"Once or twice a week\", NA, \"Not during th…\n$ psqi_5_7                &lt;chr&gt; NA, \"Once or twice a week\", NA, \"Three or more…\n$ psqi_5_8                &lt;chr&gt; NA, \"Once or twice a week\", NA, \"Once or twice…\n$ psqi_5_9                &lt;chr&gt; NA, \"Once or twice a week\", NA, \"Not during th…\n$ psqi_5_c                &lt;chr&gt; NA, \"Etiam nec nullam blandit pede duis porta …\n$ psqi_5_cr_1             &lt;chr&gt; NA, \"Not during the past month\", NA, \"Less tha…\n$ psqi_6                  &lt;int&gt; NA, 3, NA, 2, NA, NA, NA, 2, NA, 3, NA, 4, NA,…\n$ psqi_7                  &lt;int&gt; NA, 3, NA, 1, NA, NA, NA, 1, NA, 3, NA, 3, NA,…\n$ psqi_8                  &lt;int&gt; NA, 3, NA, 2, NA, NA, NA, 4, NA, 2, NA, 1, NA,…\n$ psqi_9                  &lt;int&gt; NA, 4, NA, 2, NA, NA, NA, 3, NA, 3, NA, 2, NA,…\n$ psqi_10                 &lt;int&gt; NA, 2, NA, 4, NA, NA, NA, 4, NA, 1, NA, 1, NA,…\n$ psqi_10_c_1             &lt;chr&gt; NA, \"Three or more times a week\", NA, \"Once or…\n$ psqi_10_c_2             &lt;chr&gt; NA, \"Less than once a week\", NA, \"Once or twic…\n$ psqi_10_c_3             &lt;chr&gt; NA, \"Not during the past month\", NA, \"Less tha…\n$ psqi_10_c_4             &lt;chr&gt; NA, \"Less than once a week\", NA, \"Once or twic…\n$ psqi_10_c_5             &lt;chr&gt; NA, \"Once or twice a week\", NA, \"Less than onc…\n$ psqi_10_c_5_TEXT        &lt;chr&gt; NA, \"Viverra? Praesent elit pharetra. Orci? Du…\n$ eps_1_1                 &lt;chr&gt; NA, \"No chance of dozing\", NA, \"High chance of…\n$ eps_1_2                 &lt;chr&gt; NA, \"No chance of dozing\", NA, \"No chance of d…\n$ eps_1_3                 &lt;chr&gt; NA, \"No chance of dozing\", NA, \"High chance of…\n$ eps_1_4                 &lt;chr&gt; NA, \"No chance of dozing\", NA, \"High chance of…\n$ eps_1_5                 &lt;chr&gt; NA, \"Slight chance of dozing\", NA, \"No chance …\n$ eps_1_6                 &lt;chr&gt; NA, \"High chance of dozing\", NA, \"Moderate cha…\n$ eps_1_7                 &lt;chr&gt; NA, \"High chance of dozing\", NA, \"No chance of…\n$ eps_1_8                 &lt;chr&gt; NA, \"No chance of dozing\", NA, \"High chance of…\n$ `BFI-2-XS_1`            &lt;chr&gt; \"Neutral; no opinion\", NA, NA, NA, NA, NA, \"Di…\n$ `BFI-2-XS_2`            &lt;chr&gt; \"Disagree a little\", NA, NA, NA, NA, NA, \"Agre…\n$ `BFI-2-XS_3`            &lt;chr&gt; \"Agree a little\", NA, NA, NA, NA, NA, \"Neutral…\n$ `BFI-2-XS_4`            &lt;chr&gt; \"Neutral; no opinion\", NA, NA, NA, NA, NA, \"Ag…\n$ `BFI-2-XS_5`            &lt;chr&gt; \"Agree a little\", NA, NA, NA, NA, NA, \"Agree a…\n$ `BFI-2-XS_6`            &lt;chr&gt; \"Neutral; no opinion\", NA, NA, NA, NA, NA, \"Ne…\n$ `BFI-2-XS_7`            &lt;chr&gt; \"Disagree strongly\", NA, NA, NA, NA, NA, \"Disa…\n$ `BFI-2-XS_8`            &lt;chr&gt; \"Disagree strongly\", NA, NA, NA, NA, NA, \"Disa…\n$ `BFI-2-XS_9`            &lt;chr&gt; \"Neutral; no opinion\", NA, NA, NA, NA, NA, \"Ne…\n$ `BFI-2-XS_10`           &lt;chr&gt; \"Disagree a little\", NA, NA, NA, NA, NA, \"Neut…\n$ `BFI-2-XS_11`           &lt;chr&gt; \"Neutral; no opinion\", NA, NA, NA, NA, NA, \"Ag…\n$ `BFI-2-XS_12`           &lt;chr&gt; \"Disagree a little\", NA, NA, NA, NA, NA, \"Disa…\n$ `BFI-2-XS_13`           &lt;chr&gt; \"Agree strongly\", NA, NA, NA, NA, NA, \"Neutral…\n$ `BFI-2-XS_14`           &lt;chr&gt; \"Disagree strongly\", NA, NA, NA, NA, NA, \"Agre…\n$ `BFI-2-XS_15`           &lt;chr&gt; \"Disagree a little\", NA, NA, NA, NA, NA, \"Disa…\n$ trojan_1                &lt;chr&gt; \"3\", NA, NA, NA, NA, NA, \"2\", NA, NA, NA, NA, …\n$ trojan_2                &lt;chr&gt; \"3\", NA, NA, NA, NA, NA, \"4\", NA, NA, NA, NA, …\n$ trojan_3                &lt;chr&gt; \"4\", NA, NA, NA, NA, NA, \"1 - Strongly disagre…\n$ trojan_4                &lt;chr&gt; \"2\", NA, NA, NA, NA, NA, \"3\", NA, NA, NA, NA, …\n$ trojan_5                &lt;chr&gt; \"1 - Strongly disagree\", NA, NA, NA, NA, NA, \"…\n$ trojan_6                &lt;chr&gt; \"3\", NA, NA, NA, NA, NA, \"2\", NA, NA, NA, NA, …\n$ trojan_7                &lt;chr&gt; \"4\", NA, NA, NA, NA, NA, \"2\", NA, NA, NA, NA, …\n$ trojan_8                &lt;chr&gt; \"4\", NA, NA, NA, NA, NA, \"4\", NA, NA, NA, NA, …\n$ trojan_9                &lt;chr&gt; \"2\", NA, NA, NA, NA, NA, \"4\", NA, NA, NA, NA, …\n$ trojan_10               &lt;chr&gt; \"1 - Strongly disagree\", NA, NA, NA, NA, NA, \"…\n$ trojan_11               &lt;chr&gt; \"2\", NA, NA, NA, NA, NA, \"3\", NA, NA, NA, NA, …\n$ trojan_12               &lt;chr&gt; \"2\", NA, NA, NA, NA, NA, \"1 - Strongly disagre…\n$ trojan_13               &lt;chr&gt; \"3\", NA, NA, NA, NA, NA, \"3\", NA, NA, NA, NA, …\n$ trojan_14               &lt;chr&gt; \"4\", NA, NA, NA, NA, NA, \"4\", NA, NA, NA, NA, …\n$ trojan_15               &lt;chr&gt; \"1 - Strongly disagree\", NA, NA, NA, NA, NA, \"…\n$ `selfreportPlay #1_1_1` &lt;dbl&gt; 451864991, 1854152882, 1715559403, 517546130, …\n$ `selfreportPlay #1_1_2` &lt;dbl&gt; 1573216261, 1923083539, 758663418, 1385740675,…\n$ `selfreportPlay #1_2_1` &lt;dbl&gt; 440687077, 868777931, 1138501115, 442426895, N…\n$ `selfreportPlay #1_2_2` &lt;dbl&gt; 328526617, 1627195134, 2053221620, 135050009, …\n$ `selfreportPlay #1_3_1` &lt;dbl&gt; 83312732, 865433634, 1638742542, 1343099576, N…\n$ `selfreportPlay #1_3_2` &lt;dbl&gt; 1951798264, 1769641675, 359766896, 1627439538,…\n$ recentSessions_1_1      &lt;chr&gt; \"Malesuada, convallis mattis purus accusamus m…\n$ recentSessions_1_2      &lt;chr&gt; \"Venenatis convallis. Sollicitudin blandit et …\n$ recentSessions_1_3      &lt;chr&gt; \"Potenti sagittis laoreet tellus magna. Dolor …\n$ recentSessions_1_4      &lt;chr&gt; \"Blandit est tempus a non donec platea felis. …\n$ recentSessions_2_1      &lt;chr&gt; \"Luctus maecenas malesuada elit! Sem commodo, …\n$ recentSessions_2_2      &lt;chr&gt; \"Tortor? Vitae cursus elit quam ut dolor at. M…\n$ recentSessions_2_3      &lt;chr&gt; \"Augue! Quam a id viverra interdum ipsum ultri…\n$ recentSessions_2_4      &lt;chr&gt; \"Diam! Tempus tortor tempor porta. Cursus wisi…\n$ recentSessions_3_1      &lt;chr&gt; \"Venenatis faucibus diam velit egestas malesua…\n$ recentSessions_3_2      &lt;chr&gt; \"Massa nibh per nulla orci ipsum. Laoreet dui …\n$ recentSessions_3_3      &lt;chr&gt; \"Platea nonummy sit dolorem. Pretium viverra! …\n$ recentSessions_3_4      &lt;chr&gt; \"Arcu interdum nullam per curabitur! Tempus ut…\n$ csas                    &lt;dbl&gt; 3, 4, 1, 9, NA, NA, 0, 0, 8, 0, NA, 9, 10, 3, …\n$ affectiveValence_1      &lt;dbl&gt; 44, 23, 30, 44, NA, NA, 55, 27, 10, 6, NA, 76,…\n$ wemwbs_1                &lt;chr&gt; \"2 - Rarely\", \"1 - None of the time\", \"3 - Som…\n$ wemwbs_2                &lt;chr&gt; \"5 - All of the time\", \"4 - Often\", \"2 - Rarel…\n$ wemwbs_3                &lt;chr&gt; \"5 - All of the time\", \"1 - None of the time\",…\n$ wemwbs_4                &lt;chr&gt; \"2 - Rarely\", \"2 - Rarely\", \"4 - Often\", \"2 - …\n$ wemwbs_5                &lt;chr&gt; \"5 - All of the time\", \"3 - Some of the time\",…\n$ wemwbs_6                &lt;chr&gt; \"2 - Rarely\", \"3 - Some of the time\", \"5 - All…\n$ wemwbs_7                &lt;chr&gt; \"2 - Rarely\", \"3 - Some of the time\", \"2 - Rar…\n$ wemwbs_attCheck_1       &lt;chr&gt; \"5 - All of the time\", \"1 - None of the time\",…\n$ wemwbs_attCheck_2       &lt;chr&gt; \"2 - Rarely\", \"4 - Often\", \"1 - None of the ti…\n$ wemwbs_attCheck_3       &lt;chr&gt; \"2 - Rarely\", \"1 - None of the time\", \"2 - Rar…\n$ wemwbs_attCheck_4       &lt;chr&gt; \"5 - All of the time\", \"2 - Rarely\", \"1 - None…\n$ wemwbs_attCheck_5       &lt;chr&gt; \"4 - Often\", \"4 - Often\", \"1 - None of the tim…\n$ wemwbs_attCheck_6       &lt;chr&gt; \"1 - None of the time\", \"3 - Some of the time\"…\n$ wemwbs_attCheck_7       &lt;chr&gt; \"5 - All of the time\", \"3 - Some of the time\",…\n$ promis_1                &lt;chr&gt; \"Rarely\", \"Never\", \"Sometimes\", \"Rarely\", NA, …\n$ promis_2                &lt;chr&gt; \"Always\", \"Rarely\", \"Rarely\", \"Often\", NA, NA,…\n$ promis_3                &lt;chr&gt; \"Never\", \"Often\", \"Often\", \"Always\", NA, NA, \"…\n$ promis_4                &lt;chr&gt; \"Never\", \"Always\", \"Often\", \"Never\", NA, NA, \"…\n$ promis_5                &lt;chr&gt; \"Sometimes\", \"Never\", \"Never\", \"Often\", NA, NA…\n$ promis_6                &lt;chr&gt; \"Sometimes\", \"Rarely\", \"Rarely\", \"Never\", NA, …\n$ promis_7                &lt;chr&gt; \"Rarely\", \"Often\", \"Sometimes\", \"Rarely\", NA, …\n$ promis_8                &lt;chr&gt; \"Never\", \"Sometimes\", \"Often\", \"Sometimes\", NA…\n$ bangs_1                 &lt;chr&gt; \"2\", \"4Neither Agree nor Disagree\", \"2\", \"3\", …\n$ bangs_2                 &lt;chr&gt; \"1 \\nStrongly Disagree\", \"3\", \"3\", \"1 \\nStrong…\n$ bangs_3                 &lt;chr&gt; \"2\", \"5\", \"7 Strongly agree\", \"2\", NA, NA, \"5\"…\n$ bangs_4                 &lt;chr&gt; \"4Neither Agree nor Disagree\", \"5\", \"2\", \"3\", …\n$ bangs_5                 &lt;chr&gt; \"7 Strongly agree\", \"2\", \"1 \\nStrongly Disagre…\n$ bangs_6                 &lt;chr&gt; \"4Neither Agree nor Disagree\", \"2\", \"3\", \"7 St…\n$ bangs_7                 &lt;chr&gt; \"7 Strongly agree\", \"1 \\nStrongly Disagree\", \"…\n$ bangs_8                 &lt;chr&gt; \"7 Strongly agree\", \"3\", \"7 Strongly agree\", \"…\n$ bangs_9                 &lt;chr&gt; \"6\", \"5\", \"5\", \"2\", NA, NA, \"1 \\nStrongly Disa…\n$ bangs_10                &lt;chr&gt; \"5\", \"1 \\nStrongly Disagree\", \"7 Strongly agre…\n$ bangs_11                &lt;chr&gt; \"2\", \"7 Strongly agree\", \"3\", \"2\", NA, NA, \"4N…\n$ bangs_12                &lt;chr&gt; \"2\", \"5\", \"7 Strongly agree\", \"1 \\nStrongly Di…\n$ bangs_13                &lt;chr&gt; \"2\", \"2\", \"3\", \"6\", NA, NA, \"1 \\nStrongly Disa…\n$ bangs_14                &lt;chr&gt; \"7 Strongly agree\", \"3\", \"3\", \"6\", NA, NA, \"3\"…\n$ bangs_15                &lt;chr&gt; \"1 \\nStrongly Disagree\", \"4Neither Agree nor D…\n$ bangs_16                &lt;chr&gt; \"4Neither Agree nor Disagree\", \"2\", \"7 Strongl…\n$ bangs_17                &lt;chr&gt; \"6\", \"1 \\nStrongly Disagree\", \"6\", \"5\", NA, NA…\n$ bangs_18                &lt;chr&gt; \"3\", \"2\", \"5\", \"1 \\nStrongly Disagree\", NA, NA…\n$ displacement_1          &lt;chr&gt; \"Greatly supported\", \"Slightly interfered\", \"G…\n$ displacement_2          &lt;chr&gt; \"Greatly interfered\", \"Slightly supported\", \"M…\n$ displacement_3          &lt;chr&gt; \"Slightly supported\", \"No impact\", \"Moderately…\n$ displacement_4          &lt;chr&gt; \"Slightly supported\", \"No impact\", \"Greatly su…\n$ displacement_5          &lt;chr&gt; \"Greatly supported\", \"No impact\", \"Moderately …\n\n\n\n\n\n2.4.2 Diary\n\n\nShow code (simulate diary data)\nsynDiary &lt;- expand.grid(pid = synIntake$pid[synIntake$region == \"US\"], day = 1:diaryWaves) |&gt;\n  mutate(\n    date = studyDates[day],\n    surveyCompletionTime = date + seconds(runif(n(), 64800, 93600)) # add time so that the survey is randomly completed between 6pm and 2am\n  ) |&gt;\n  # bootstrap each column from the non-NA values in the original data\n  cbind(map_dfc(datDiary, ~ rep(sample(.[!is.na(.)], length(.), replace = TRUE),\n    length.out = length(synIntake$pid[synIntake$region == \"US\"]) * diaryWaves\n  ))) |&gt;\n  # join with missingness df\n  left_join(dropout |&gt; filter(!is.na(diaryWave)) |&gt; select(pid, diaryWave, missingDiary),\n    by = c(\"pid\", \"day\" = \"diaryWave\")\n  ) |&gt;\n  # remove data for all missing diary waves, and removing gaming data when the\n  # participant didn't play in the last 24 hours\n  mutate(\n    across(-c(pid, day, date, missingDiary), ~ if_else(missingDiary, NA, .)),\n    across(starts_with(c(\"socialGaming\", \"bangs\", \"mostRecentGame\", \"displaced\")), ~ ifelse(played24hr == \"No\", NA, .)) # remove gaming data\n  ) |&gt;\n  # clean up\n  select(pid, day, date, missingDiary, everything()) |&gt;\n  arrange(as.integer(pid), day) |&gt;\n  copy_labels(datDiary)\n\n\n\n\nClick to view the structure of the diary data\n\n\nglimpse(synDiary)\n\nRows: 21,000\nColumns: 70\n$ pid                  &lt;chr&gt; \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\",…\n$ day                  &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15…\n$ date                 &lt;date&gt; 2024-05-01, 2024-05-02, 2024-05-03, 2024-05-04, …\n$ missingDiary         &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, …\n$ surveyCompletionTime &lt;dttm&gt; 2024-05-01 19:17:25, 2024-05-02 19:12:14, 2024-0…\n$ played24hr           &lt;ord&gt; Yes, Yes, No, Yes, Yes, Yes, No, No, Yes, No, No,…\n$ socialGaming_4       &lt;chr&gt; \"Single-player games only\", \"Single-player games …\n$ socialGaming_5       &lt;chr&gt; \"Multiplayer with real-world friends\", \"Multiplay…\n$ socialGaming_6       &lt;chr&gt; \"Multiplayer with online-only friends\", \"Multipla…\n$ socialGaming_7       &lt;chr&gt; \"Multiplayer with strangers\", \"Multiplayer with s…\n$ mostRecentGame       &lt;chr&gt; \"Rhoncus lacus egestas imperdiet augue mo\", \"Prae…\n$ bangs_1              &lt;chr&gt; \"2\", \"5\", NA, \"4Neither Agree nor Disagree\", \"5\",…\n$ bangs_2              &lt;chr&gt; \"2\", \"3\", NA, \"1 \\nStrongly Disagree\", \"4Neither …\n$ bangs_3              &lt;chr&gt; \"5\", \"3\", NA, \"4Neither Agree nor Disagree\", \"6\",…\n$ bangs_4              &lt;chr&gt; \"4Neither Agree nor Disagree\", \"1 \\nStrongly Disa…\n$ bangs_5              &lt;chr&gt; \"5\", \"6\", NA, \"7 Strongly agree\", \"5\", \"6\", NA, N…\n$ bangs_6              &lt;chr&gt; \"2\", \"4Neither Agree nor Disagree\", NA, \"5\", \"4Ne…\n$ displacedActivity    &lt;chr&gt; \"Nonummy placerat? Phasellus placerat. Tincidunt …\n$ lifeSat_1            &lt;dbl&gt; 32, 98, 89, 30, 59, 51, 51, 75, 57, 85, 33, 74, 7…\n$ affectiveValence_1   &lt;dbl&gt; 52, 95, 43, 81, 65, 92, 52, 38, 46, 57, 60, 81, 4…\n$ bpnsfs_1             &lt;chr&gt; \"2 - strongly disagree\", \"4 - neither disagree no…\n$ bpnsfs_2             &lt;chr&gt; \"4 - neither disagree nor agree\", \"5 - agree\", \"3…\n$ bpnsfs_3             &lt;chr&gt; \"5 - agree\", \"3 - disagree\", \"5 - agree\", \"1 - ve…\n$ bpnsfs_4             &lt;chr&gt; \"5 - agree\", \"3 - disagree\", \"4 - neither disagre…\n$ bpnsfs_5             &lt;chr&gt; \"3 - disagree\", \"4 - neither disagree nor agree\",…\n$ bpnsfs_6             &lt;chr&gt; \"5 - agree\", \"1 - very strongly disagree\", \"1 - v…\n$ sd_0                 &lt;ord&gt; Vacation day, Other (please specify):, Weekend, H…\n$ sd_0_8_TEXT          &lt;chr&gt; \"Felis? Posuere magna ipsum volutpat, gravida ab …\n$ `sd_1#1_1_1`         &lt;dbl&gt; 1603849685, 894379514, 735841771, 1602488313, 128…\n$ `sd_1#1_1_2`         &lt;dbl&gt; 1567469283, 1691810101, 930545705, 862698895, 791…\n$ `sd_1#2_1`           &lt;chr&gt; \"AM\", \"PM\", \"PM\", \"AM\", \"PM\", \"PM\", \"AM\", \"AM\", \"…\n$ `sd_2#1_1_1`         &lt;dbl&gt; 485500086, 104054518, 1169408008, 140056431, 1836…\n$ `sd_2#1_1_2`         &lt;dbl&gt; 1204348752, 1861270655, 545564080, 238349578, 981…\n$ `sd_2#2_1`           &lt;chr&gt; \"AM\", \"PM\", \"PM\", \"PM\", \"PM\", \"AM\", \"PM\", \"AM\", \"…\n$ sd_3                 &lt;dbl&gt; 2132146993, 1606313892, 1789753926, 1804958614, 1…\n$ `sd_4#1_1_1`         &lt;dbl&gt; 466056748, 307429782, 1257880481, 286159513, 1318…\n$ `sd_4#1_1_2`         &lt;dbl&gt; 851300260, 1380056229, 719718577, 870500403, 1275…\n$ `sd_4#2_1`           &lt;chr&gt; \"AM\", \"PM\", \"AM\", \"AM\", \"PM\", \"PM\", \"PM\", \"AM\", \"…\n$ `sd_5#1_1_1`         &lt;dbl&gt; 341739502, 242494822, 1001144473, 1130461394, 208…\n$ `sd_5#1_1_2`         &lt;dbl&gt; 1255753273, 1468794244, 824672027, 2002728982, 51…\n$ `sd_5#2_1`           &lt;chr&gt; \"AM\", \"AM\", \"PM\", \"PM\", \"AM\", \"PM\", \"PM\", \"PM\", \"…\n$ sd_6                 &lt;ord&gt; Good, Very good, Fair, Very poor, Very poor, Very…\n$ timeUse_5            &lt;dbl&gt; 6, 10, 7, 10, 0, 13, 14, 4, 1, 13, 2, 13, 5, 0, 8…\n$ timeUse_6            &lt;dbl&gt; 14, 1, 14, 1, 10, 7, 7, 6, 9, 12, 3, 1, 4, 10, 4,…\n$ timeUse_1            &lt;dbl&gt; 7, 7, 4, 1, 2, 0, 6, 4, 0, 1, 3, 3, 1, 0, 10, 1, …\n$ timeUse_2            &lt;dbl&gt; 0, 2, 0, 7, 6, 3, 1, 7, 0, 2, 11, 2, 1, 0, 2, 1, …\n$ timeUse_3            &lt;dbl&gt; 1.0, 0.0, 0.0, 0.0, 4.1, 0.0, 8.0, 1.0, 0.0, 0.0,…\n$ timeUse_4            &lt;dbl&gt; 2, 0, 4, 2, 0, 0, 2, 1, 0, 5, 2, 0, 1, 0, 0, 0, 2…\n$ timeUse_7            &lt;dbl&gt; 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2…\n$ timeUse_8            &lt;dbl&gt; 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ timeUse_9            &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1…\n$ timeUse_10           &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ timeUse_11           &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ timeUse_12           &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ timeUse_13           &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ timeUse_14           &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ stress_argument      &lt;ord&gt; No, No, Yes, No, No, Yes, No, No, No, Yes, Yes, N…\n$ howStress_arg        &lt;chr&gt; \"Not very\", \"Not at all\", \"Very\", \"Somewhat\", \"Ve…\n$ stress_letpass       &lt;ord&gt; Yes, Yes, No, No, Yes, Yes, Yes, No, Yes, Yes, Ye…\n$ howStress_letPass    &lt;ord&gt; Somewhat, Very, Not very, Not very, Not very, Som…\n$ stress_school        &lt;ord&gt; No, Yes, No, No, Yes, Yes, No, Yes, Yes, No, No, …\n$ howStress_school     &lt;ord&gt; Not very, Not very, Very, Somewhat, Somewhat, Som…\n$ stress_home          &lt;ord&gt; No, Yes, Yes, Yes, Yes, Yes, Yes, No, No, Yes, Ye…\n$ howStress_home       &lt;ord&gt; Not very, Very, Not very, Very, Not at all, Very,…\n$ stress_discrim       &lt;ord&gt; No, No, No, No, No, Yes, No, No, No, No, Yes, No,…\n$ howStress_discrim    &lt;ord&gt; Not at all, Not at all, Not at all, Not at all, S…\n$ stress_relative      &lt;ord&gt; No, Yes, Yes, No, No, No, Yes, Yes, Yes, No, No, …\n$ howStress_relative   &lt;ord&gt; Not very, Very, Not at all, Somewhat, Very, Very,…\n$ stress_other         &lt;ord&gt; No, No, No, No, No, Yes, No, Yes, No, Yes, Yes, Y…\n$ howStress_other      &lt;ord&gt; Very, Not at all, Not at all, Very, Very, Not ver…",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Generate Synthetic Data</span>"
    ]
  },
  {
    "objectID": "0_generateSyntheticData.html#generate-codebook",
    "href": "0_generateSyntheticData.html#generate-codebook",
    "title": "2  Generate Synthetic Data",
    "section": "2.5 Generate Codebook",
    "text": "2.5 Generate Codebook\nGenerate codebook.xlsx.\n\n\nShow code (generate codebook\nmetaInfo &lt;- tribble(\n  ~Tab, ~`Data File`, ~Content,\n  \"Intake\", \"data-synthetic/synIntake.csv.gz\", \"Data on participant demographics and gaming habits\",\n  \"Panel\", \"data-synthetic/synPanel.csv.gz\", \"Wellbeing, sleep and time use data from the panel survey\",\n  \"Diary\", \"data-synthetic/synDiary.csv.gz\", \"Daily diary data on gaming, wellbeing, and sleep\",\n  \"Nintendo\", \"data-synthetic/synNintendo.csv.gz\", \"Telemetry data (session-level) from the Nintendo Switch\",\n  \"Xbox\", \"data-synthetic/synXbox.csv.gz\", \"Telemetry data (session-level) from Xbox devices\",\n  \"Steam\", \"data-synthetic/synSteam.csv.gz\", \"Telemetry data (total playtime in 1 hour blocks) from Steam\",\n  \"iOS\", \"data-synthetic/syniOS.csv.gz\", \"Screen time data from iOS devices, pulled from screenshots of the Screen time app\",\n  \"Android\", \"data-synthetic/synAndroid.csv.gz\", \"App usage data from Android devices, pulled from ActivityWatch\"\n)\n\nintakeCodebook &lt;- synIntake |&gt;\n  get_label() |&gt;\n  enframe() |&gt;\n  separate(value, into = c(\"stem\", \"item\"), sep = \" - \", extra = \"merge\", fill = \"right\", remove = FALSE) |&gt;\n  mutate(\n    Item = if_else(is.na(item), value, item),\n    `Stem text` = if_else(grepl(\" - \", value), stem, NA),\n    .keep = \"unused\"\n  )\n\npanelCodebook &lt;- synPanel |&gt;\n  get_label() |&gt;\n  enframe() |&gt;\n  separate(value, into = c(\"stem\", \"item\"), sep = \" - \", extra = \"drop\", fill = \"right\", remove = FALSE) |&gt;\n  mutate(\n    Item = if_else(is.na(item), value, item),\n    `Stem text` = if_else(grepl(\" - \", value), stem, NA),\n    .keep = \"unused\"\n  ) |&gt;\n  mutate(\n    Source = case_when(\n      grepl(\"wemwbs\", name) ~ \"Warwick-Edinburgh Mental Wellbeing Scale (https://doi.org/10.1186/1477-7525-5-63)\",\n      grepl(\"promis\", name) ~ \"PROMIS Short Form 8a Adult Depression Scale (https://doi.org/10.1177/1073191111411667)\",\n      grepl(\"bangs\", name) ~ \"Basic Needs in Games Scale (https://doi.org/10.31234/osf.io/4965z7)\",\n      grepl(\"trojan\", name) ~ \"Trojan Player Typology (https://doi.org/10.1016/j.chb.2015.03.018)\",\n      grepl(\"gdt\", name) ~ \"Gaming Disorder Test (https://doi.org/10.1007/s11469-019-00088-z)\",\n      grepl(\"mctq\", name) ~ \"Munich Chronotype Questionnaire (https://doi.org/10.1177/0748730402239679)\",\n      grepl(\"pqsi\", name) ~ \"Pittsburgh Sleep Quality Index (https://doi.org/10.1016/0165-1781(89)90047-4)\",\n      grepl(\"eps\", name) ~ \"Epwoth Sleepiness Scale (https://doi.org/10.1093/sleep/14.6.540)\",\n      grepl(\"BFI\", name) ~ \"Extra-short Big Five Inventory–2 (https://doi.org/10.1016/j.jrp.2017.02.004)\",\n      grepl(\"lifeSat\", name) ~ \"Cantril Self-anchoring Scale (Cantril, 1965)\",\n      TRUE ~ \"\"\n    ),\n    `Response Options` = case_when(\n      grepl(\"wemwbs\", name) ~ \"1 - None of the time; 2 - Rarely; 3 - Some of the time; 4 - Often; 5 - All of the time\",\n      grepl(\"promis\", name) ~ \"Never; Rarely; Sometimes; Often; Never\",\n      grepl(\"bangs\", name) ~ \"1 Strongly Disagree; 2; 3; 4 Neither Agree nor Disagree; 5; 6; 7 Strongly Agree\",\n      grepl(\"trojan\", name) ~ \"1 - Strongly disagree; 2; 3; 4; 5 - Strongly agree\",\n      name %in% c(\"problematicPlay\", \"positives\") ~ \"free text response\",\n      grepl(\"displacement\", name) ~ \"Greatly interfered; Moderately interfered; Slightly interfered; No impact; Slightly supported;\nModerately supported; Greatly supported\",\n      grepl(\"timeUse\", name) ~ \"slider from 0-16 hours, with increments of .1\",\n      grepl(\"eps\", name) ~ \"No chance of dozing; Slight chance of dozing; Moderate chance of dozing; High chance of dozing\",\n      grepl(\"BFI\", name) ~ \"Disagree strongly; Disagree a little; Neutral, no opinion; Agree a little; Agree strongly\",\n      grepl(\"lifeSat\", name) ~ \"1-100 sliding scale\",\n      TRUE ~ \"\"\n    ),\n    `Stem text` = gsub(\"[\\r\\n]\", \"\", `Stem text`)\n  ) |&gt;\n  rename(Variable = name)\n\ndiaryCodebook &lt;- synDiary |&gt;\n  get_label() |&gt;\n  enframe() |&gt;\n  separate(value, into = c(\"stem\", \"item\"), sep = \" - \", extra = \"drop\", fill = \"right\", remove = FALSE) |&gt;\n  mutate(\n    Item = if_else(is.na(item), value, item),\n    `Stem text` = if_else(grepl(\" - \", value), stem, NA),\n    .keep = \"unused\"\n  ) |&gt;\n  mutate(\n    Source = case_when(\n      grepl(\"bangs\", name) ~ \"Basic Needs in Games Scale (https://doi.org/10.31234/osf.io/4965z7)\",\n      grepl(\"bpnsfs\", name) ~ \"Basic Psychological Need Satisfaction and Frustration Scale (https://doi.org/10.1007/s11031-014-9450-1), brief version (https://doi.org/1015-5759/a000846)\",\n      grepl(\"stress|howStress\", name) ~ \"Daily Inventory of Stressful Events (https://doi.org/10.1177/1073191102091006)\",\n      grepl(\"sd_\", name) ~ \"Consensus Sleep Diary (https://doi.org/10.5665/sleep.1642)\",\n      grepl(\"lifeSat\", name) ~ \"Cantril Self-anchoring Scale (Cantril, 1965)\",\n      TRUE ~ \"\"\n    ),\n    `Response Options` = case_when(\n      grepl(\"bangs\", name) ~ paste(names(table(synDiary$bangs_1)), collapse = \"; \"),\n      grepl(\"bpnsfs\", name) ~ paste(names(table(synDiary$bpnsfs_1)), collapse = \"; \"),\n      grepl(\"timeUse\", name) ~ \"slider from 0-16 hours, with increments of .1\",\n      grepl(\"^stress\", name) ~ \"Yes; No\",\n      grepl(\"howStress\", name) ~ \"Not at all; Not very; Somewhat; Very\",\n      name == \"sd_0\" ~ \"Regular work day; Regular day off; Weekend; Holiday; Vacation day Other (please specify):\",\n      grepl(\"lifeSat\", name) ~ \"1-100 sliding scale\",\n      TRUE ~ \"\"\n    ),\n    `Stem text` = gsub(\"[\\r\\n]\", \"\", `Stem text`)\n  ) |&gt;\n  rename(Variable = name)\n\nnintendoCodebook &lt;- synNintendo |&gt;\n  var_labels(\n    pid = \"A unique identifier assigned to each participant in the study.\",\n    day = \"The day number relative to the start of the study (e.g., Day 1, Day 2).\",\n    date = \"The calendar date on which the gaming session occurred (format: YYYY-MM-DD).\",\n    session = \"A sequential identifier for each gaming session on a given day for the participant.\",\n    titleID = \"The name of the game played during the session.\",\n    sessionStart = \"The time of day when the gaming session began (format: HH:MM:SS).\",\n    duration = \"The length of the gaming session in minutes.\",\n    genre = \"The genre(s) of the game played (e.g., Action, Puzzle, Role-Playing), using IGDB categories.\",\n    platform = \"The platform on which the game was played, for use in future merging (here: always Nintendo).\"\n  ) |&gt;\n  get_label() |&gt;\n  enframe(name = \"Variable\", value = \"Description\") |&gt;\n  mutate(Notes = case_when(\n    Variable == \"genre\" ~ paste0(\"Possible genres are: \", paste(uniqueGenres, collapse = \", \")),\n    TRUE ~ \"\"\n  ))\n\nxboxCodebook &lt;- synXbox |&gt;\n  var_labels(\n    pid = \"A unique identifier assigned to each participant in the study.\",\n    day = \"The day number relative to the start of the study (e.g., Day 1, Day 2).\",\n    date = \"The calendar date on which the gaming session occurred (format: YYYY-MM-DD).\",\n    session = \"A sequential identifier for each gaming session on a given day for the participant.\",\n    titleID = \"The name of the game played during the session.\",\n    sessionStart = \"The time of day when the gaming session began (format: HH:MM:SS).\",\n    duration = \"The length of the gaming session in minutes.\",\n    genre = \"The genre(s) of the game played using IGDB categories.\",\n    platform = \"The platform on which the game was played, for use in future merging (here: always Xbox).\"\n  ) |&gt;\n  get_label() |&gt;\n  enframe(name = \"Variable\", value = \"Description\") |&gt;\n  mutate(Notes = case_when(\n    Variable == \"genre\" ~ paste0(\"Possible genres are: \", paste(uniqueGenres, collapse = \", \")),\n    TRUE ~ \"\"\n  ))\n\nsteamCodebook &lt;- synSteam |&gt;\n  var_labels(\n    pid = \"A unique identifier assigned to each participant in the study.\",\n    day = \"The day number relative to the start of the study (e.g., Day 1, Day 2).\",\n    date = \"The calendar date on which the gaming session occurred (format: YYYY-MM-DD).\",\n    hour = \"The hour of the day when the gaming session began (0-23).\",\n    persona = \"One of 250 possible Steam personas, generated by LLMs, with particular gameplay habits\",\n    genre = \"The genre(s) of the game played using IGDB categories.\",\n    minutes = \"The number of minutes played of that game during the hour period in question.\",\n    AppID = \"A unique identifier assigned to each game on the Steam platform.\",\n    Name = \"The name of the game played during the session.\",\n    platform = \"The platform on which the game was played, for use in future merging (here: always Steam).\"\n  ) |&gt;\n  get_label() |&gt;\n  enframe(name = \"Variable\", value = \"Description\") |&gt;\n  mutate(Notes = case_when(\n    Variable == \"genre\" ~ paste0(\"Possible genres are: \", paste(uniqueGenres, collapse = \", \")),\n    TRUE ~ \"\"\n  ))\n\niOSCodebook &lt;- syniOS |&gt;\n  var_labels(\n    missing = \"Indicator for whether the data for the week is missing (TRUE = missing).\",\n    dropout = \"Indicator for whether the participant dropped out of the study (TRUE = dropped out).\",\n    pid = \"A unique identifier assigned to each participant in the study.\",\n    week = \"The week number relative to the start of the study.\",\n    date = \"The date corresponding to the start of the week in question (format: YYYY-MM-DD).\",\n    Entertainment = \"Total amount of time spent in entertainment apps during the week (in minutes).\",\n    Social = \"Total amount of time spent in social media apps during the week (in minutes).\",\n    `Information & Reading` = \"Total amount of time spent in information and reading apps during the week (in minutes).\",\n    Games = \"Total amount of time spent in gaming apps during the week (in minutes).\",\n    `Productivity & Finance` = \"Total amount of time spent in productivity and finance apps during the week (in minutes).\",\n    Travel = \"Total amount of time spent in travel-related apps during the week (in minutes).\",\n    Other = \"Total amount of time spent in other uncategorized apps during the week (in minutes).\",\n    Creativity = \"Total amount of time spent in creativity apps (e.g., photo/video editing) during the week (in minutes).\",\n    Education = \"Total amount of time spent in educational apps during the week (in minutes).\",\n    `Health & Fitness` = \"Total amount of time spent in health and fitness apps during the week (in minutes).\",\n    `Shopping & Food` = \"Total amount of time spent in shopping and food-related apps during the week (in minutes).\",\n    Utilities = \"Total amount of time spent in utility apps (e.g., weather, calculators) during the week (in minutes).\",\n    totalScreentime = \"Total amount of screen time across all app categories during the week (in minutes).\"\n  ) |&gt;\n  get_label() |&gt;\n  enframe(name = \"Variable\", value = \"Description\")\n\nandroidCodebook &lt;- synAndroid |&gt;\n  var_labels(\n    pid = \"A unique identifier assigned to each participant in the study.\",\n    day = \"The day number relative to the start of the study (e.g., Day 1, Day 2).\",\n    numDailyAppSessions = \"The total number of app sessions recorded on the given day.\",\n    date = \"The calendar date on which the app sessions occurred (format: YYYY-MM-DD).\",\n    session = \"A sequential identifier for each app session on the given day for the participant.\",\n    app = \"The name of the app used during the session.\",\n    sessionStart = \"The time of day when the app session began (format: HH:MM:SS).\",\n    duration = \"The duration of the app session in minutes.\",\n    category = \"The category of the app used during the session (e.g., Social, Productivity, Entertainment).\"\n  ) |&gt;\n  get_label() |&gt;\n  enframe(name = \"Variable\", value = \"Description\")\n\n# Generate and format codebook\nwrite.xlsx(\n  list(\n    \"Meta-info\" = metaInfo,\n    \"Intake\" = intakeCodebook,\n    \"Panel\" = panelCodebook,\n    \"Diary\" = diaryCodebook,\n    \"Nintendo\" = nintendoCodebook,\n    \"Xbox\" = xboxCodebook,\n    \"Steam\" = steamCodebook,\n    \"iOS\" = iOSCodebook,\n    \"Android\" = androidCodebook\n  ),\n  file = \"codebook.xlsx\",\n  headerStyle = createStyle(textDecoration = \"bold\", halign = \"center\"),\n  overwrite = TRUE,\n  colWidths = \"auto\"\n)\n\ncodebook &lt;- loadWorkbook(\"codebook.xlsx\")\naddStyle(codebook, \"Meta-info\", rows = nrow(metaInfo) + 3, cols = 1:3, style = createStyle(wrapText = TRUE))\nsetColWidths(codebook, \"Intake\", cols = 1:3, widths = c(25, 100, 40))\nsetColWidths(codebook, \"Panel\", cols = 1:3, widths = c(25, 100, 40))\nsetColWidths(codebook, \"Diary\", cols = 1:3, widths = c(25, 100, 40))\naddStyle(codebook, \"Intake\", rows = nrow(intakeCodebook) + 3, cols = 1:3, style = createStyle(wrapText = TRUE))\naddStyle(codebook, \"Panel\", rows = nrow(panelCodebook) + 3, cols = 1:3, style = createStyle(wrapText = TRUE))\naddStyle(codebook, \"Diary\", rows = nrow(diaryCodebook) + 3, cols = 1:3, style = createStyle(wrapText = TRUE))\nwriteData(codebook, \"Meta-info\", startRow = nrow(metaInfo) + 3, startCol = 1, x = \"Tabs of this file contain the respective codebooks for each data table.\")\nmergeCells(codebook, \"Meta-info\", cols = 1:3, rows = nrow(metaInfo) + 3)\nsetRowHeights(codebook, \"Meta-info\", rows = nrow(metaInfo) + 3, heights = 50)\nsaveWorkbook(codebook, \"codebook.xlsx\", overwrite = TRUE)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Generate Synthetic Data</span>"
    ]
  },
  {
    "objectID": "0_generateSyntheticData.html#save-data",
    "href": "0_generateSyntheticData.html#save-data",
    "title": "2  Generate Synthetic Data",
    "section": "2.6 Save data",
    "text": "2.6 Save data\nSave the data to data-synthetic, for use in devising analysis scripts for e.g. the registered reports to come.\n\n\nShow code (save data)\n# Export as compressed CSV\nwrite_csv(synIntake, \"data-synthetic/synIntake.csv.gz\")\nwrite_csv(synDiary, \"data-synthetic/synDiary.csv.gz\")\nwrite_csv(synPanel, \"data-synthetic/synPanel.csv.gz\")\nwrite_csv(synXbox, \"data-synthetic/synXbox.csv.gz\")\nwrite_csv(synNintendo, \"data-synthetic/synNintendo.csv.gz\")\nwrite_csv(synAndroid, \"data-synthetic/synAndroid.csv.gz\")\nwrite_csv(synSteam, \"data-synthetic/synSteam.csv.gz\")\nwrite_csv(syniOS, \"data-synthetic/syniOS.csv.gz\")",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Generate Synthetic Data</span>"
    ]
  },
  {
    "objectID": "1_preprocess.html",
    "href": "1_preprocess.html",
    "title": "3  Preprocess Data",
    "section": "",
    "text": "3.1 Preamble\nShow the code (options)\nknitr::opts_chunk$set(\n  echo = knitr::is_html_output(),\n  warning = FALSE,\n  message = FALSE,\n  output = TRUE\n)\n\nset.seed(8675309)\nShow the code (libraries)\nif (!require(\"pacman\")) install.packages(\"pacman\")\nlibrary(pacman)\n\np_load(tidyverse, mctq, data.table)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Preprocess Data</span>"
    ]
  },
  {
    "objectID": "1_preprocess.html#load-data",
    "href": "1_preprocess.html#load-data",
    "title": "3  Preprocess Data",
    "section": "3.2 Load data",
    "text": "3.2 Load data\n\n\nShow the code (load data)\nsynDiary &lt;- read_csv(\"data-synthetic/synDiary.csv.gz\")\n\n# for unknown reasons, read_csv imports some columns incorrectly, so we use data.table::fread\nsynPanel &lt;- fread(\"data-synthetic/synPanel.csv.gz\") \nsynIntake &lt;- read_csv(\"data-synthetic/synIntake.csv.gz\")\n\nsynNintendo &lt;- read_csv(\"data-synthetic/synNintendo.csv.gz\") |&gt;\n  mutate(sessionEnd = sessionStart + minutes(round(duration)), .after = sessionStart)\nsynXbox &lt;- read_csv(\"data-synthetic/synXbox.csv.gz\") |&gt;\n  mutate(sessionEnd = sessionStart + minutes(round(duration)), .after = sessionStart)\nsynSteam &lt;- read_csv(\"data-synthetic/synSteam.csv.gz\") |&gt; \n  mutate(sessionStart = date + hours(hour))",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Preprocess Data</span>"
    ]
  },
  {
    "objectID": "1_preprocess.html#clean-intake",
    "href": "1_preprocess.html#clean-intake",
    "title": "3  Preprocess Data",
    "section": "3.3 Clean intake",
    "text": "3.3 Clean intake\n\n\nShow the code (clean intake)\nsynIntakeClean &lt;- synIntake |&gt;\n  # define socio-economic status (SES) index\n  mutate(\n    # Assigning scores to employment categories\n    empScore = case_when(\n      employment == \"Full-Time\" ~ 5,\n      employment == \"Part-Time\" ~ 4,\n      employment == \"Due to start a new job within the next month\" ~ 3,\n      employment == \"Not in paid work (e.g. homemaker', 'retired or disabled)\" ~ 2,\n      employment == \"Unemployed (and job seeking)\" ~ 1,\n      employment == \"Other\" ~ NA_real_ ,  # Adjust based on context if necessary\n      TRUE ~ NA_real_  # Handle any other cases\n    ),\n    \n    # Assigning scores to education levels\n    eduScore = case_when(\n      eduLevel == \"Graduate or professional degree (MA, MS, MBA, PhD, etc)\" ~ 7,\n      eduLevel == \"University Bachelors Degree\" ~ 6,\n      eduLevel == \"Some University but no degree\" ~ 5,\n      eduLevel == \"Vocational or Similar\" ~ 4,\n      eduLevel == \"Completed Secondary School\" ~ 3,\n      eduLevel == \"Some Secondary\" ~ 2,\n      eduLevel == \"Completed Primary School\" ~ 1,\n      eduLevel == \"Some Primary\" ~ 1,\n      eduLevel == \"Prefer not to say\" ~ NA_real_,  # Treat as missing\n      TRUE ~ NA_real_  # Handle any other cases\n    ),\n    \n    # Combining the scores into a SES index\n    SES_index = empScore + eduScore\n  ) |&gt; \n  mutate(\n    # Calculate total height in inches\n    total_inches = `height#1_1_1` * 12 + `height#1_1_2`,\n    \n    # Calculate BMI using the formula\n    bmi = (weight / (total_inches^2)) * 703,\n\n    age_scaled = as.numeric(scale(age, center = TRUE, scale = TRUE)),\n    bmi_scaled = as.numeric(scale(bmi, center = TRUE, scale = TRUE)),\n    SES_index_scaled = as.numeric(scale(SES_index, center = TRUE, scale = TRUE))\n  )",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Preprocess Data</span>"
    ]
  },
  {
    "objectID": "1_preprocess.html#clean-diary",
    "href": "1_preprocess.html#clean-diary",
    "title": "3  Preprocess Data",
    "section": "3.4 Clean diary",
    "text": "3.4 Clean diary\nHere we want to: - recode the diary data to numeric values - calculate mean scores of relevant variables - calculate within- and between-person centered variables - recode the displaced activity data into categories (randomly assigned, for now) - calculate some variables based on the telemetry\n\n\nShow the code (clean diary)\nsynDiaryClean &lt;- synDiary |&gt;\n  mutate(\n    across(starts_with(c(\"bpnsfs\", \"bangs\")), ~ case_when(\n      . %in% c(\"1 \\nStrongly Disagree\", \"1 - Not at all true\", \"1 - very strongly disagree\") ~ 1,\n      . %in% c(\"2\", \"2 - strongly disagree\") ~ 2,\n      . %in% c(\"3\", \"3 - disagree\") ~ 3,\n      . %in% c(\"4Neither Agree nor Disagree\", \"4\", \"4 - neither disagree nor agree\") ~ 4,\n      . %in% c(\"5\", \"5 - Completely true\", \"5 - agree\") ~ 5,\n      . %in% c(\"6\") ~ 6,\n      . %in% c(\"7 Strongly agree\") ~ 7,\n      TRUE ~ NA_integer_\n    ))\n  ) %&gt;%\n  # calculate mean scores of relevant variables (there is no missing data within waves)\n  mutate(\n    globalNS = rowMeans(select(., bpnsfs_1:bpnsfs_3), na.rm = TRUE),\n    globalNF = rowMeans(select(., bpnsfs_4:bpnsfs_6), na.rm = TRUE),\n    gameNS = rowMeans(select(., bangs_1:bangs_3), na.rm = TRUE),\n    gameNF = rowMeans(select(., bangs_4:bangs_6), na.rm = TRUE)\n  ) |&gt;\n  # Calculate within- and between-person centered variables\n  group_by(pid) %&gt;%\n  mutate(across(\n    c(globalNS, globalNF, gameNS, gameNF),\n    list(\n      cw = ~ . - mean(., na.rm = TRUE),\n      cb = ~ mean(., na.rm = TRUE)\n    )\n  )) %&gt;%\n  ungroup() %&gt;%\n  mutate(across(\n    ends_with(\"cb\"),\n    ~ . - mean(., na.rm = TRUE)\n  )) |&gt;\n  # to understand displaced activities, we will manually code the true\n  # participant activity data into categories. We pre-define 5 problematic\n  # displacement categories (work/school, social engagements, sleep, eating,\n  # fitness, caretaking) and one catch-all category (other), which may later be\n  # broken down into subcategories.\n  mutate(\n    displacedActivityCategory = ifelse(!is.na(displacedActivity),\n      sample(c(\"work/school\", \"social engagements\", \"sleep\", \"eating\", \"fitness\", \"caretaking\", \"other\"),\n        n(),\n        prob = c(.05, .05, .05, .05, .05, .05, .75),\n        replace = TRUE\n      ),\n      NA_character_\n    ),\n    displacedCoreDomain = ifelse(displacedActivityCategory %in% c(\n      \"work/school\", \"social engagements\",\n      \"sleep\", \"eating\", \"fitness\", \"caretaking\", \"other\"\n    ),\n    TRUE,\n    FALSE\n    ),\n    .after = displacedActivity\n  )",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Preprocess Data</span>"
    ]
  },
  {
    "objectID": "1_preprocess.html#clean-panel",
    "href": "1_preprocess.html#clean-panel",
    "title": "3  Preprocess Data",
    "section": "3.5 Clean panel",
    "text": "3.5 Clean panel\nHere we want to: - recode the panel data to numeric values - calculate mean scores of relevant variables - calculate within- and between-person centered variables\n\n3.5.1 Chronotype\n\n\n\n\n\n\nNote\n\n\n\nSome notes on Chronotype:\n\n\nChronotype or sleep-corrected local time of mid-sleep on work-free days msf_sc() allows you to compute the chronotype, or corrected local time of mid-sleep on work-free days. It takes five arguments: msf (local time of mid-sleep on work-free days), sd_w (sleep duration on workdays), sd_f (sleep duration on work-free days), sd_week(average weekly sleep duration), and alarm_f (a logical object indicating if the respondent uses an alarm clock to wake up on work-free days).\nIf sd_f is less or equal than sd_w, the output must be msf. Else, it must return msf minus the difference between sd_f and sd_week divided by 2. msf_sc can only be computed if alarm_f is equal to FALSE (the function will return NA when alarm_f == TRUE).\nmsf_sc applies a correction to msf, removing an estimation of the effect from accumulated sleep debt on workdays that usually is compensated on work-free days. See ?msf_sc to learn more.\n\n\nShow the code (clean panel)\nsynPanelClean &lt;- synPanel |&gt;\n  mutate(\n    across(starts_with(c(\"bangs\", \"wemwbs\", \"promis\", \"trojan\", \"BFI\", \"eps\")), ~ case_when(\n      . %in% c(\"Greatly interfered\") ~ -3,\n      . %in% c(\"Moderately interfered\") ~ -2,\n      . %in% c(\"Slightly interfered\") ~ -1,\n      . %in% c(\"No impact\",\"No chance of dozing\") ~ 0,\n      . %in% c(\n        \"1 \\nStrongly Disagree\", \"1 - Not at all true\", \"1 - None of the time\", \"Never\", \"1 - Strongly disagree\",\n        \"Disagree strongly\", \"Slightly supported\", \"Slight chance of dozing\"\n      ) ~ 1,\n      . %in% c(\"2\", \"2 - Rarely\", \"Rarely\", \"Disagree a little\", \"Moderately supported\", \"Moderate chance of dozing\") ~ 2,\n      . %in% c(\"3\", \"3 - Some of the time\", \"Sometimes\", \"Neutral; no opinion\", \"Greatly supported\", \"High chance of dozing\") ~ 3,\n      . %in% c(\"4Neither Agree nor Disagree\", \"4\", \"4 - Often\", \"Often\", \"Agree a little\") ~ 4,\n      . %in% c(\"5\", \"5 - Completely true\", \"5 - All of the time\", \"Always\", \"5 - Strongly agree\", \"Agree strongly\") ~ 5,\n      . %in% c(\"6\") ~ 6,\n      . %in% c(\"7 Strongly agree\") ~ 7,\n      TRUE ~ NA_integer_\n    ))\n  ) %&gt;%\n  # calculate mean/sum scores of relevant variables (there is no missing data within waves)\n  mutate(\n    wemwbs = rowMeans(select(., wemwbs_1:wemwbs_7), na.rm = TRUE),\n    promis = rowMeans(select(., promis_1:promis_8), na.rm = TRUE),\n    gameNS = rowMeans(select(., bangs_1:bangs_3, bangs_7:bangs_9, bangs_13:bangs_15), na.rm = TRUE),\n    gameNF = rowMeans(select(., bangs_4:bangs_6, bangs_10:bangs_12, bangs_16:bangs_18), na.rm = TRUE),\n    epsTotal = rowSums(select(., eps_1_1:eps_1_8), na.rm = TRUE),\n  ) |&gt;\n  # Calculate within- and between-person centered variables\n  group_by(pid) %&gt;%\n  mutate(across(\n    c(wemwbs, promis, gameNS, gameNF),\n    list(\n      cw = ~ . - mean(., na.rm = TRUE),\n      cb = ~ mean(., na.rm = TRUE)\n    )\n  )) %&gt;%\n  ungroup() %&gt;%\n  mutate(across(\n    ends_with(\"cb\"),\n    ~ . - mean(., na.rm = TRUE)\n  )) |&gt; \n\n  # calculate amount of sleep\n  mutate(\n    psqi_4_1_1_1_hours = as.numeric(`psqi_4#1_1_1`), # Convert hours to numeric\n    psqi_4_1_1_2_hours = as.numeric(`psqi_4#1_1_2`) / 60, # Convert minutes to numeric hours\n    total_hours_sleep = psqi_4_1_1_1_hours + psqi_4_1_1_2_hours, # Compute total hours of sleep\n    .keep = \"unused\"\n  ) |&gt; \n\n  # ~~~~~~~~~~~~~~~~~~~~~~~~~\n  # calculate chronotype ####\n  # ~~~~~~~~~~~~~~~~~~~~~~~~\n  \n  # rename mctq_1 to work  and turn it into a logical variable where 1 is 1 and 2 is 0, other is NA\n   mutate(work = case_when(\n    mctq_1 == 1 ~ 1,\n    mctq_1 == 2 ~ 0,\n    TRUE ~ NA_real_\n   )) |&gt; \n   rename(\n    wd = mctq_2_1, \n    bt_w = mctq_3_1, \n    sprep_w = mctq_3_3, \n    slat_w = mctq_3_4, \n    se_w = mctq_3_5, \n    si_w = mctq_3_6,\n    bt_f = mctq_6_1, \n    sprep_f = mctq_6_3, \n    slat_f = mctq_6_4, \n    se_f = mctq_6_5, \n    si_f = mctq_6_6,\n    reasons_why_f = mctq_8_1\n  ) |&gt; \n  mutate(\n    alarm_w = case_when(\n      mctq_4_1 == \"Yes\" ~ 1,\n      mctq_4_1 == \"No\" ~ 0,\n      TRUE ~ NA_real_),\n    wake_before_w = case_when(\n      mctq_5_1 == \"Yes\" ~ 1,\n      mctq_5_1 == \"No\" ~ 0,\n      TRUE ~ NA_real_\n    ),\n    alarm_f = case_when(\n      mctq_7_1 == \"Yes\" ~ 1,\n      mctq_7_1 == \"No\" ~ 0,\n      TRUE ~ NA_real_\n    ),\n    reasons_f = case_when(\n      mctq_7_2 == \"Yes\" ~ 1,\n      mctq_7_2 == \"No\" ~ 0,\n      TRUE ~ NA_real_\n    ),\n  ) |&gt;\n  mutate(\n    across(\"wd\", as.integer),\n    across(matches(\"^work$|^alarm_|^wake_|^reasons_f$\"), as.logical),\n    across(matches(\"^bt_|^sprep_|^se_\"), hms::parse_hm),\n    across(matches(\"^slat_|^si_\"), ~ dminutes(as.numeric(.x)))\n  ) |&gt; \n  # Calculate sleep onset\n  mutate(\n    so_w = mctq::so(sprep_w, slat_w),\n    so_f = mctq::so(sprep_f, slat_f)\n  ) |&gt;\n  # Calculate sleep duration\n  mutate(\n    sd_w = mctq::sdu(so_w, se_w),\n    sd_f = mctq::sdu(so_f, se_f)\n  ) |&gt;\n  # Calculate midsleep time\n  mutate(\n    msw = mctq::msl(so_w, sd_w),\n    msf = mctq::msl(so_f, sd_f)\n  ) |&gt;\n  # Calculate weekly sleep duration\n  mutate(\n    sd_week = mctq::sd_week(sd_w, sd_f, wd)\n  ) |&gt; \n  # Calculate chronotype\n  mutate(\n    msf_sc = mctq::msf_sc(msf, sd_w, sd_f, sd_week, alarm_f),\n    msf_sc_numeric = as.numeric(msf_sc) / 3600\n  )",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Preprocess Data</span>"
    ]
  },
  {
    "objectID": "1_preprocess.html#process-telemetry",
    "href": "1_preprocess.html#process-telemetry",
    "title": "3  Preprocess Data",
    "section": "3.6 Process telemetry",
    "text": "3.6 Process telemetry\n\n\nShow the code (process telemetry)\n# TODO: make sure that sessions happening as late as 6 hours later are still included, even if this isn't on the same day\n\n# in the below, we join the survey data to each telemetry table,\n# and filter for only the sessions/rows that happened immediately after the survey was completed.\n# after, we join these back together with a binary indicator of whether at least one session occurred\n\nnintendoOverlaps &lt;- synDiaryClean %&gt;%\n  left_join(synNintendo, by = c(\"pid\", \"day\", \"date\")) |&gt;\n  filter(\n    sessionEnd &gt;= surveyCompletionTime | # Session ended after the survey time\n      sessionStart &lt;= surveyCompletionTime + days(1) # Session started before the end of the time window\n  ) |&gt;\n  group_by(pid, day, date) |&gt;\n  summarize(playedLaterNintendo = TRUE, .groups = \"drop\")\n\nxboxOverlaps &lt;- synDiaryClean %&gt;%\n  left_join(synXbox, by = c(\"pid\", \"day\", \"date\")) |&gt;\n  filter(\n    sessionEnd &gt;= surveyCompletionTime | # Session ended after the survey time\n      sessionStart &lt;= surveyCompletionTime + days(1) # Session started before the end of the time window\n  ) |&gt;\n  group_by(pid, day, date) |&gt;\n  summarize(playedLaterXbox = TRUE, .groups = \"drop\")\n\nsteamOverlaps &lt;- synDiaryClean %&gt;%\n  left_join(synSteam, by = c(\"pid\", \"day\", \"date\")) |&gt;\n  filter(\n    sessionStart &lt;= surveyCompletionTime + days(1) # Session started before the end of the time window\n  ) |&gt;\n  group_by(pid, day, date) |&gt;\n  summarize(playedLaterSteam = TRUE, .groups = \"drop\")\n\n\n# Step 3: Determine if any Nintendo sessions occurred in the time window for each row in df\nsynDiaryClean &lt;- synDiaryClean |&gt;\n  left_join(\n    nintendoOverlaps,\n    by = c(\"pid\", \"day\", \"date\")\n  ) |&gt;\n  left_join(\n    xboxOverlaps,\n    by = c(\"pid\", \"day\", \"date\")\n  ) |&gt;\n  left_join(\n    steamOverlaps,\n    by = c(\"pid\", \"day\", \"date\")\n  ) |&gt;\n  mutate(\n    playedLaterNintendo = if_else(is.na(playedLaterNintendo), FALSE, playedLaterNintendo),\n    playedLaterXbox = if_else(is.na(playedLaterXbox), FALSE, playedLaterXbox),\n    playedLaterSteam = if_else(is.na(playedLaterSteam), FALSE, playedLaterSteam),\n    playedLaterAny = ifelse(playedLaterNintendo | playedLaterXbox | playedLaterSteam, TRUE, FALSE)\n  )",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Preprocess Data</span>"
    ]
  },
  {
    "objectID": "1_preprocess.html#exclusion-criteria",
    "href": "1_preprocess.html#exclusion-criteria",
    "title": "3  Preprocess Data",
    "section": "3.7 Exclusion criteria",
    "text": "3.7 Exclusion criteria\nWe will exclude any telemetry rows wherein players have logged more than 24 hours of playtime on one platform in any single day, or where sessions have taken place in the future, indicating a technical problem or manipulation of the system clock for in-game benefits.\nWe will further include an attention check in the panel surveys whereby participants are given a random duplicated item from the need satisfaction and frustration measure. Responses where the two duplicate items differ by more than 1 scale point will be flagged for manual inspection of potential careless responding.\n\n\nShow the code (exclusion criteria)\nexcluded &lt;- bind_rows(synNintendo, synXbox, synSteam) |&gt; \n  group_by(pid, day) |&gt; \n  summarise(dailyPlay = sum(duration)) |&gt; \n  filter(dailyPlay &gt;= 1440)\n\nsynNintendoClean &lt;- synNintendo |&gt; \n  filter(sessionStart &lt;= Sys.time()) |&gt; # no future sessions\n  anti_join(excluded, by = c(\"pid\", \"day\"))\n\nsynSteamClean &lt;- synSteam |&gt; \n  filter(sessionStart &lt;= Sys.time()) |&gt; # no future sessions\n  anti_join(excluded, by = c(\"pid\", \"day\"))\n\nsynXboxClean &lt;- synXbox |&gt;\n  filter(sessionStart &lt;= Sys.time()) |&gt; # no future sessions\n  anti_join(excluded, by = c(\"pid\", \"day\"))",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Preprocess Data</span>"
    ]
  },
  {
    "objectID": "1_preprocess.html#impute-missing-data",
    "href": "1_preprocess.html#impute-missing-data",
    "title": "3  Preprocess Data",
    "section": "3.8 Impute missing data",
    "text": "3.8 Impute missing data\nHere we give an indicative example of how multiple imputation will be performed. As this is computationally demanding and will ultimately depend on the parameters of the true data, we do not exhaustively simulate imputation here. Broadly, we:\n\nPivot the data to wide format\nSelect relevant predictors for imputation so as to reduce the data size (which would otherwise include thousands of columns)\nPerform multiple imputation using predictive mean match\n\nWe will evaluate this imputation model for performance and adjust as necessary.\n\n\nShow the code (multiple imputation)\ndiaryWide &lt;- diary |&gt;\n  select(-date) |&gt;\n  pivot_wider(\n    names_from = day,\n    values_from = -pid,\n    names_sep = \"_w\"\n  ) |&gt;\n  select(-starts_with(c(\"day\", \"missing\", \"surveyCompletion\", \"sd\", \"timeUse\", \"displacedActivity\", \"playedLater\")))\n\nquickpred(diaryWide)\n\nmice(data = diaryWide, m = 5, method = \"pmm\", maxit = 5, seed = 8675309)\nmice(data = diaryWide, m = 5, method = \"pmm\", maxit = 5, parallelseed = 8675309) # alternatively, try to parallelize",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Preprocess Data</span>"
    ]
  },
  {
    "objectID": "1_preprocess.html#save-data",
    "href": "1_preprocess.html#save-data",
    "title": "3  Preprocess Data",
    "section": "3.9 Save data",
    "text": "3.9 Save data\n\n\nShow the code (save data)\nwrite_csv(synIntakeClean, \"data-synthetic/synIntakeClean.csv.gz\")\nwrite_csv(synDiaryClean, \"data-synthetic/synDiaryClean.csv.gz\")\nwrite_csv(synPanelClean, \"data-synthetic/synPanelClean.csv.gz\")\nwrite_csv(synNintendoClean, \"data-synthetic/synNintendoClean.csv.gz\")\nwrite_csv(synXboxClean, \"data-synthetic/synXboxClean.csv.gz\")\nwrite_csv(synSteamClean, \"data-synthetic/synSteamClean.csv.gz\")",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Preprocess Data</span>"
    ]
  },
  {
    "objectID": "2_basicNeeds.html",
    "href": "2_basicNeeds.html",
    "title": "4  Study 1: Gaming and Basic Needs",
    "section": "",
    "text": "5 &lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD\nShow the code\ndiaryWide &lt;- diary |&gt;\n  select(-date) |&gt;\n  pivot_wider(\n    names_from = day,\n    values_from = -pid,\n    names_sep = \"_w\"\n  ) |&gt;\n  select(-starts_with(c(\"day\", \"missing\", \"surveyCompletion\", \"sd\", \"timeUse\", \"displacedActivity\", \"playedLater\")))\n\nquickpred(diaryWide)\n\nmice(data = diaryWide, m = 5, method = \"pmm\", maxit = 5, seed = 8675309)\nmice(data = diaryWide, m = 5, method = \"pmm\", maxit = 5, parallelseed = 8675309) # alternatively, try to parallelize",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Study 1: Gaming and Basic Needs</span>"
    ]
  },
  {
    "objectID": "2_basicNeeds.html#h1.-greater-in-game-need-satisfaction-is-associated-with-greater-global-need-satisfaction-h6-in-bang",
    "href": "2_basicNeeds.html#h1.-greater-in-game-need-satisfaction-is-associated-with-greater-global-need-satisfaction-h6-in-bang",
    "title": "4  Study 1: Gaming and Basic Needs",
    "section": "5.1 H1. Greater in-game need satisfaction is associated with greater global need satisfaction (H6 in BANG)",
    "text": "5.1 H1. Greater in-game need satisfaction is associated with greater global need satisfaction (H6 in BANG)\n\n\n\n\n\n\nNote\n\n\n\nHm. Something weird is happening here - there’s a small but consistent negative relationship between gameNS_cw and globalNS, even though these variables have nothing to do with each other. I suspect this is a data issue, but I’m not sure what’s going on.\n\n\nExperiences of gaming feed into and co-constitute experiences of life as a whole—experiences with games are one (greater or lesser) element of lives in general. Thus, H6 in BANG predicts: Greater in-game need satisfaction is associated with greater global need satisfaction.\nWe model this with a multilevel within-between linear regression whereby game-level need satisfaction (within- and between-centered; gameNS_cw and gameNS_cb) predicts deviation from a person’s typical globalNS (globalNS, with a random intercept).\nThis model, in contrast to the others, has some covariates in it, mostly as a reminder to myself to figure out whether these warrant including or not.\n\n\nShow the code (H1 model)\nh1mod &lt;- glmmTMB(globalNS ~ gameNS_cw + gameNS_cb + (1 + gameNS_cw | pid) + ar1(day + 0 | pid),\n  data = dat\n)\n\nplot_predictions(h1mod, condition = \"gameNS_cw\", vcov = TRUE)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Study 1: Gaming and Basic Needs</span>"
    ]
  },
  {
    "objectID": "2_basicNeeds.html#h2.-situational-need-satisfaction-is-positively-associated-with-the-likelihood-of-playing-in-the-period-after-survey-completion-h2a-while-global-need-frustration-is-negatively-associated-h2b",
    "href": "2_basicNeeds.html#h2.-situational-need-satisfaction-is-positively-associated-with-the-likelihood-of-playing-in-the-period-after-survey-completion-h2a-while-global-need-frustration-is-negatively-associated-h2b",
    "title": "4  Study 1: Gaming and Basic Needs",
    "section": "5.2 H2. Situational need satisfaction is positively associated with the likelihood of playing in the period after survey completion (H2a), while global need frustration is negatively associated (H2b)",
    "text": "5.2 H2. Situational need satisfaction is positively associated with the likelihood of playing in the period after survey completion (H2a), while global need frustration is negatively associated (H2b)\nExperiences of need satisfaction during a particular gaming session lead players to update expectations for future experiences with the current game, similar games, and gaming as a whole, such that greater need satisfaction leads to higher expectations for future need satisfaction. Under BANG, need-related outcome expectations are conceptually similar to intrinsic motivation, and the behavioral product of these expectations is therefore greater behavioral engagement.\nThus, the model attempts to evaluate whether experiencing high game-level need satisfaction in one’s most recent session is linked with a higher likelihood of playing games again in the 24-hour period after the survey.\nAnother factor that might increase the likelihood that someone (re)turns to gaming is global need frustration. SDT predicts that (global) need frustration results in compensatory behavior—people attempt to replenish needs that are not being met by altering their behavior. The dense need satisfaction offered by games constitute one way for people to compensate. BANG operationalizes this compensatory play in via intrinsic motivation. Frustrated needs in one’s life in general make opportunities to fulfill those needs more salient, which—all else equal—manifests phenomenologically as an increased energy towards those activities. Given this, we predict: Global need frustration is associated with higher likelihood of playing in the 24-hour period after survey completion (H9 in BANG)\nAs they share an outcome variable, we model these together. We model these with a multilevel within-between logistic regression, where in-game need satisfaction and global need frustration (each within- and between-person centered; gameNS_cw, gameNS_cb, globalNF_cw, globalNF_cb) predict playedAfterSurvey, a binary variable indicating whether any play happened in the 24-hour period after diary survey completion.\nAs before, we include an AR(1) term to account for the fact that likelihood of play might be autocorrelated (if, e.g., people tend to get on a role and play multiple days in a row).\n\n\nShow the code (H2 model)\nh2mod &lt;- glmmTMB(\n  playedLaterAny ~ gameNS_cw + gameNS_cb + globalNF_cw + globalNF_cb +\n    (1 + gameNS_cw + globalNF_cw | pid) + ar1(day + 0 | pid),\n  data = dat,\n  family = binomial(link = \"logit\"),\n  dispformula = ~1,\n  ziformula = ~0\n)\n\nplot_predictions(h2mod, condition = \"globalNF_cw\", vcov = TRUE)\n\n\n\n\n\n\n\n\n\nShow the code (H2 model)\nplot_predictions(h2mod, condition = \"gameNS_cw\", vcov = TRUE)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Study 1: Gaming and Basic Needs</span>"
    ]
  },
  {
    "objectID": "2_basicNeeds.html#h3.-when-gaming-displaces-a-core-life-domain-workschool-social-engagements-sleepeatingfitness-or-caretaking-global-need-satisfaction-will-be-lower-h5-in-bang",
    "href": "2_basicNeeds.html#h3.-when-gaming-displaces-a-core-life-domain-workschool-social-engagements-sleepeatingfitness-or-caretaking-global-need-satisfaction-will-be-lower-h5-in-bang",
    "title": "4  Study 1: Gaming and Basic Needs",
    "section": "5.3 H3. When gaming displaces a core life domain (work/school, social engagements, sleep/eating/fitness, or caretaking), global need satisfaction will be lower (H5 in BANG)",
    "text": "5.3 H3. When gaming displaces a core life domain (work/school, social engagements, sleep/eating/fitness, or caretaking), global need satisfaction will be lower (H5 in BANG)\nWe don’t have temporal precedence here (the need satisfaction measure refers to the day as a whole), and have very little ability to define and adjust for confounds, so this is a very weak test of the displacement hypothesis—but the first of its kind, as far as I know.\nBriefly, I’m just interested in whether gaming sessions that displace a core life domain—work/school, social engagements, sleep/eating/fitness, or caretaking—are associated with lower global need satisfaction. displacedCoreActivity is a binary variable; participants write in a free text response what they most likely would have done instead of their most recent gaming session, and these are classified into core/noncore domains.\nWe use a multilevel linear regression to determine whether displacing a core activity is likely to co-occur with a person differing from their typical level of global need satisfaction (globalNS).\n\n\nShow the code (H3 model)\ntable(dat$displacedCoreDomain)\n\n\n\nFALSE  TRUE \n14031  6969 \n\n\nShow the code (H3 model)\nh3mod &lt;- glmmTMB(globalNS ~ displacedCoreDomain + (1 + displacedCoreDomain | pid) + ar1(day + 0 | pid),\n  data = dat\n)\nplot_predictions(h3mod, condition = \"displacedCoreDomain\", vcov = TRUE)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Study 1: Gaming and Basic Needs</span>"
    ]
  },
  {
    "objectID": "3_sleep.html",
    "href": "3_sleep.html",
    "title": "5  Study 2: Gaming and Sleep",
    "section": "",
    "text": "5.1 H1a: Late-night gaming is associated with poorer sleep quality.\nMultilevel ordinal regression whereby monthly average minutes played predicts sleep quality (PSQI), controlling for age, BMI, SES index, region, and whether playtime falls on a weekend, with a random intercept and slope for participants.\nFit H1a model\n# For psqi_6 1 means Very good, 2 means Fairly good, 3 means Fairly bad, 4 means Very bad\n\n# Fit the model with rescaled covariates\nmodel.h1a &lt;- clmm(psqi_6_ord ~ monthly_avg_minutes_played + (1 + monthly_avg_minutes_played | pid) +\n                    age_scaled + bmi_scaled + SES_index_scaled + region + isWeekend,\n                  data = gamingMonthly)\n\nmodelsummary(\n  list(`Model H1a` = model.h1a),\n  fmt = 2,\n  estimate  = \"{estimate} [{conf.low}, {conf.high}]{stars}\", \n  statistic = NULL\n)\n\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                Model H1a\n              \n        \n        \n        \n                \n                  1|2                                           \n                  -1.46 [-1.62, -1.30]***\n                \n                \n                  2|3                                           \n                  -0.01 [-0.16, 0.15]    \n                \n                \n                  3|4                                           \n                  1.48 [1.32, 1.64]***   \n                \n                \n                  monthly_avg_minutes_played                    \n                  0.11 [-0.17, 0.40]     \n                \n                \n                  age_scaled                                    \n                  -0.12 [-0.24, 0.00]*   \n                \n                \n                  bmi_scaled                                    \n                  0.04 [-0.04, 0.13]     \n                \n                \n                  SES_index_scaled                              \n                  0.07 [-0.02, 0.15]     \n                \n                \n                  regionUS                                      \n                  -0.13 [-0.37, 0.11]    \n                \n                \n                  isWeekend                                     \n                  -0.01 [-0.10, 0.09]    \n                \n                \n                  SD (Intercept pid)                            \n                  1.40                   \n                \n                \n                  SD (monthly_avg_minutes_played pid)           \n                  0.48                   \n                \n                \n                  Cor (Intercept~monthly_avg_minutes_played pid)\n                  -0.84                  \n                \n                \n                  Num.Obs.                                      \n                  6329                   \n                \n                \n                  R2 Marg.                                      \n                  0.003                  \n                \n                \n                  R2 Cond.                                      \n                  0.375                  \n                \n                \n                  AIC                                           \n                  16749.3                \n                \n                \n                  BIC                                           \n                  16830.3                \n                \n                \n                  RMSE                                          \n                  2.39",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Study 2: Gaming and Sleep</span>"
    ]
  },
  {
    "objectID": "3_sleep.html#h1b-late-night-gaming-is-associated-with-shorter-sleep-duration.",
    "href": "3_sleep.html#h1b-late-night-gaming-is-associated-with-shorter-sleep-duration.",
    "title": "5  Study 2: Gaming and Sleep",
    "section": "5.2 H1b: Late-night gaming is associated with shorter sleep duration.",
    "text": "5.2 H1b: Late-night gaming is associated with shorter sleep duration.\nMultilevel linear regression whereby monthly average minutes played predicts total hours of sleep (PSQI), controlling for age, BMI, SES index, region, gender, and whether playtime falls on a weekend, with a random intercept and slope for participants and a random intercept for gender.\n\n\nFit H1b model\n# Fit the model\nmodel.h1b &lt;- lmer(total_hours_sleep ~ monthly_avg_minutes_played + (1 + monthly_avg_minutes_played | pid) +\n                    age_scaled + bmi_scaled + SES_index_scaled + (1 | gender) + region + isWeekend, \n                  data = gamingMonthly)\n\n# Summarize the model using modelsummary\nmodelsummary(\n  list(`Model H1b` = model.h1b),\n  fmt = 2,\n  estimate  = \"{estimate} [{conf.low}, {conf.high}]{stars}\", \n  statistic = NULL\n)\n\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                Model H1b\n              \n        \n        \n        \n                \n                  (Intercept)                                   \n                  6.64 [6.41, 6.86]***\n                \n                \n                  monthly_avg_minutes_played                    \n                  -0.40 [-0.91, 0.10] \n                \n                \n                  age_scaled                                    \n                  -0.07 [-0.24, 0.10] \n                \n                \n                  bmi_scaled                                    \n                  -0.03 [-0.15, 0.10] \n                \n                \n                  SES_index_scaled                              \n                  -0.03 [-0.15, 0.10] \n                \n                \n                  regionUS                                      \n                  -0.05 [-0.39, 0.29] \n                \n                \n                  isWeekend                                     \n                  0.04 [-0.11, 0.18]  \n                \n                \n                  SD (Intercept pid)                            \n                  1.97                \n                \n                \n                  SD (monthly_avg_minutes_played pid)           \n                  0.67                \n                \n                \n                  Cor (Intercept~monthly_avg_minutes_played pid)\n                  -0.42               \n                \n                \n                  SD (Intercept gender)                         \n                  0.00                \n                \n                \n                  SD (Observations)                             \n                  2.92                \n                \n                \n                  Num.Obs.                                      \n                  6329                \n                \n                \n                  R2 Marg.                                      \n                  0.001               \n                \n                \n                  AIC                                           \n                  33144.0             \n                \n                \n                  BIC                                           \n                  33225.1             \n                \n                \n                  RMSE                                          \n                  2.69",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Study 2: Gaming and Sleep</span>"
    ]
  },
  {
    "objectID": "3_sleep.html#h1c-late-night-gaming-is-associated-with-lower-well-being.",
    "href": "3_sleep.html#h1c-late-night-gaming-is-associated-with-lower-well-being.",
    "title": "5  Study 2: Gaming and Sleep",
    "section": "5.3 H1c: Late-night gaming is associated with lower well-being.",
    "text": "5.3 H1c: Late-night gaming is associated with lower well-being.\nMultilevel linear regression whereby monthly average minutes played predicts daytime sleepiness (Epworth Sleepiness Scale), controlling for age, BMI, SES index, region, gender, and whether playtime falls on a weekend, with a random intercept and slope for participants and a random intercept for gender.\n\n\nFit H1c model\nmodel.h1c &lt;- lmer(wemwbs ~ biweekly_avg_minutes_played + (1 + biweekly_avg_minutes_played | pid) +\n                    age_scaled + bmi_scaled + SES_index_scaled + (1 | gender) + region + isWeekend, \n                  data = gamingBiweekly)\n\nmodelsummary(\n  list(`Model H1c` = model.h1c),\n  fmt = 2,\n  estimate  = \"{estimate} [{conf.low}, {conf.high}]{stars}\", \n  statistic = NULL\n)\n\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                Model H1c\n              \n        \n        \n        \n                \n                  (Intercept)                                    \n                  2.98 [2.96, 3.00]***\n                \n                \n                  biweekly_avg_minutes_played                    \n                  0.00 [-0.01, 0.01]  \n                \n                \n                  age_scaled                                     \n                  0.02 [0.00, 0.04]+  \n                \n                \n                  bmi_scaled                                     \n                  0.01 [0.00, 0.02]+  \n                \n                \n                  SES_index_scaled                               \n                  0.00 [-0.01, 0.02]  \n                \n                \n                  regionUS                                       \n                  0.03 [0.00, 0.07]+  \n                \n                \n                  isWeekend                                      \n                  0.00 [-0.02, 0.02]  \n                \n                \n                  SD (Intercept pid)                             \n                  0.20                \n                \n                \n                  SD (biweekly_avg_minutes_played pid)           \n                  0.00                \n                \n                \n                  Cor (Intercept~biweekly_avg_minutes_played pid)\n                  -1.00               \n                \n                \n                  SD (Intercept gender)                          \n                  0.00                \n                \n                \n                  SD (Observations)                              \n                  0.50                \n                \n                \n                  Num.Obs.                                       \n                  12599               \n                \n                \n                  R2 Marg.                                       \n                  0.001               \n                \n                \n                  AIC                                            \n                  19675.9             \n                \n                \n                  BIC                                            \n                  19765.2             \n                \n                \n                  RMSE                                           \n                  0.48",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Study 2: Gaming and Sleep</span>"
    ]
  },
  {
    "objectID": "3_sleep.html#h1d-late-night-gaming-is-associated-with-higher-daytime-sleepiness.",
    "href": "3_sleep.html#h1d-late-night-gaming-is-associated-with-higher-daytime-sleepiness.",
    "title": "5  Study 2: Gaming and Sleep",
    "section": "5.4 H1d: Late-night gaming is associated with higher daytime sleepiness.",
    "text": "5.4 H1d: Late-night gaming is associated with higher daytime sleepiness.\nMultilevel linear regression whereby biweekly average minutes played predicts well-being (WEMWBS), controlling for age, BMI, SES index, region, gender, and whether playtime falls on a weekend, with a random intercept and slope for participants and a random intercept for gender.\n\n\nFit H1d model\n# Fit the model\nmodel.h1d &lt;- lmer(epsTotal ~ monthly_avg_minutes_played + (1 + monthly_avg_minutes_played | pid) +\n                    age_scaled + bmi_scaled + SES_index_scaled + (1 | gender) + region + isWeekend, \n                  data = gamingMonthly)\n\n# Summarize the model using modelsummary\nmodelsummary(\n  list(`Model H1d` = model.h1d),\n  fmt = 2,\n  estimate  = \"{estimate} [{conf.low}, {conf.high}]{stars}\", \n  statistic = NULL\n)\n\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                Model H1d\n              \n        \n        \n        \n                \n                  (Intercept)                                   \n                  7.06 [6.69, 7.43]***\n                \n                \n                  monthly_avg_minutes_played                    \n                  -0.06 [-0.47, 0.35] \n                \n                \n                  age_scaled                                    \n                  0.05 [-0.24, 0.35]  \n                \n                \n                  bmi_scaled                                    \n                  0.09 [-0.12, 0.30]  \n                \n                \n                  SES_index_scaled                              \n                  -0.09 [-0.30, 0.12] \n                \n                \n                  regionUS                                      \n                  0.24 [-0.34, 0.82]  \n                \n                \n                  isWeekend                                     \n                  0.00 [-0.19, 0.18]  \n                \n                \n                  SD (Intercept pid)                            \n                  4.20                \n                \n                \n                  SD (monthly_avg_minutes_played pid)           \n                  0.20                \n                \n                \n                  Cor (Intercept~monthly_avg_minutes_played pid)\n                  1.00                \n                \n                \n                  SD (Intercept gender)                         \n                  0.00                \n                \n                \n                  SD (Observations)                             \n                  4.86                \n                \n                \n                  Num.Obs.                                      \n                  10650               \n                \n                \n                  R2 Marg.                                      \n                  0.001               \n                \n                \n                  AIC                                           \n                  67014.1             \n                \n                \n                  BIC                                           \n                  67101.4             \n                \n                \n                  RMSE                                          \n                  4.50",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Study 2: Gaming and Sleep</span>"
    ]
  },
  {
    "objectID": "3_sleep.html#h2",
    "href": "3_sleep.html#h2",
    "title": "5  Study 2: Gaming and Sleep",
    "section": "5.5 H2",
    "text": "5.5 H2\n\n5.5.1 H2a: The negative association between late-night gaming and sleep quality is more pronounced among evening chronotypes.\nMultilevel ordinal regression whereby the interaction between monthly average minutes played and chronotype (MSFsc: mid-sleep on free days corrected for sleep debt on weekdays; MCTQ) predicts sleep quality (PSQI), controlling for age, BMI, SES index, region, and whether playtime falls on a weekend, with a random intercept and slope for participants.\n\n\nFit H2a model\n# Fit the model with rescaled covariates\nmodel.h2a &lt;- clmm(psqi_6_ord ~ monthly_avg_minutes_played * msf_sc_numeric + (1 + monthly_avg_minutes_played | pid) +\n                    age_scaled + bmi_scaled + SES_index_scaled + region + isWeekend,\n                  data = gamingMonthly)\n\nmodelsummary(\n  list(`Model H2a` = model.h2a),\n  fmt = 2,\n  estimate  = \"{estimate} [{conf.low}, {conf.high}]{stars}\", \n  statistic = NULL\n)\n\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                Model H2a\n              \n        \n        \n        \n                \n                  1|2                                           \n                  -1.42 [-1.75, -1.09]***\n                \n                \n                  2|3                                           \n                  0.00 [-0.33, 0.32]     \n                \n                \n                  3|4                                           \n                  1.50 [1.16, 1.83]***   \n                \n                \n                  monthly_avg_minutes_played                    \n                  -2.03 [-4.93, 0.88]    \n                \n                \n                  msf_sc_numeric                                \n                  -0.01 [-0.03, 0.01]    \n                \n                \n                  age_scaled                                    \n                  -0.10 [-0.28, 0.09]    \n                \n                \n                  bmi_scaled                                    \n                  -0.10 [-0.23, 0.03]    \n                \n                \n                  SES_index_scaled                              \n                  0.02 [-0.12, 0.15]     \n                \n                \n                  regionUS                                      \n                  0.00 [-0.37, 0.36]     \n                \n                \n                  isWeekend                                     \n                  -0.01 [-0.15, 0.14]    \n                \n                \n                  monthly_avg_minutes_played × msf_sc_numeric   \n                  0.09 [-0.04, 0.22]     \n                \n                \n                  SD (Intercept pid)                            \n                  1.39                   \n                \n                \n                  SD (monthly_avg_minutes_played pid)           \n                  0.04                   \n                \n                \n                  Cor (Intercept~monthly_avg_minutes_played pid)\n                  1.00                   \n                \n                \n                  Num.Obs.                                      \n                  2661                   \n                \n                \n                  R2 Marg.                                      \n                  0.013                  \n                \n                \n                  R2 Cond.                                      \n                  0.377                  \n                \n                \n                  AIC                                           \n                  7046.9                 \n                \n                \n                  BIC                                           \n                  7129.3                 \n                \n                \n                  RMSE                                          \n                  2.36",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Study 2: Gaming and Sleep</span>"
    ]
  },
  {
    "objectID": "3_sleep.html#h2b-the-negative-association-between-late-night-gaming-and-sleep-duration-is-more-pronounced-among-evening-chronotypes.",
    "href": "3_sleep.html#h2b-the-negative-association-between-late-night-gaming-and-sleep-duration-is-more-pronounced-among-evening-chronotypes.",
    "title": "5  Study 2: Gaming and Sleep",
    "section": "5.6 H2b: The negative association between late-night gaming and sleep duration is more pronounced among evening chronotypes.",
    "text": "5.6 H2b: The negative association between late-night gaming and sleep duration is more pronounced among evening chronotypes.\n\n\nFit H2b model\n# Fit the model\nmodel.h2b &lt;- lmer(total_hours_sleep ~ monthly_avg_minutes_played * msf_sc_numeric + (1 + monthly_avg_minutes_played | pid) +\n                    age_scaled + bmi_scaled + SES_index_scaled + region + isWeekend + (1 | gender), \n                  data = gamingMonthly)\n\n# Summarize the model using modelsummary\nmodelsummary(\n  list(`Model H2b` = model.h2b),\n  fmt = 2,\n  estimate  = \"{estimate} [{conf.low}, {conf.high}]{stars}\", \n  statistic = NULL\n)\n\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                Model H2b\n              \n        \n        \n        \n                \n                  (Intercept)                                   \n                  6.79 [6.28, 7.30]***\n                \n                \n                  monthly_avg_minutes_played                    \n                  -0.72 [-3.25, 1.81] \n                \n                \n                  msf_sc_numeric                                \n                  -0.01 [-0.04, 0.02] \n                \n                \n                  age_scaled                                    \n                  -0.19 [-0.46, 0.08] \n                \n                \n                  bmi_scaled                                    \n                  0.02 [-0.18, 0.21]  \n                \n                \n                  SES_index_scaled                              \n                  -0.04 [-0.23, 0.16] \n                \n                \n                  regionUS                                      \n                  -0.09 [-0.62, 0.44] \n                \n                \n                  isWeekend                                     \n                  -0.01 [-0.23, 0.22] \n                \n                \n                  monthly_avg_minutes_played × msf_sc_numeric   \n                  0.02 [-0.11, 0.16]  \n                \n                \n                  SD (Intercept pid)                            \n                  1.95                \n                \n                \n                  SD (monthly_avg_minutes_played pid)           \n                  1.58                \n                \n                \n                  Cor (Intercept~monthly_avg_minutes_played pid)\n                  -0.88               \n                \n                \n                  SD (Intercept gender)                         \n                  0.22                \n                \n                \n                  SD (Observations)                             \n                  2.94                \n                \n                \n                  Num.Obs.                                      \n                  2661                \n                \n                \n                  R2 Marg.                                      \n                  0.003               \n                \n                \n                  R2 Cond.                                      \n                  0.314               \n                \n                \n                  AIC                                           \n                  13991.8             \n                \n                \n                  BIC                                           \n                  14074.2             \n                \n                \n                  ICC                                           \n                  0.3                 \n                \n                \n                  RMSE                                          \n                  2.71                \n                \n        \n      \n    \n\n\n\n\n5.6.1 H2c: The negative association between late-night gaming and well-being is more pronounced among evening chronotypes.\nMultilevel linear regression whereby the interaction between monthly average minutes played and chronotype (MSFsc; MCTQ) predicts daytime sleepiness (Epworth Sleepiness Scale), controlling for age, BMI, SES index, region, gender, and whether playtime falls on a weekend, with a random intercept and slope for participants and a random intercept for gender.\n\n\nFit H2c model\n# Fit the model\nmodel.h2c &lt;- lmer(wemwbs ~ biweekly_avg_minutes_played * msf_sc_numeric + (1 | pid) +\n                    age_scaled + bmi_scaled + SES_index_scaled + region + isWeekend + (1 | gender), \n                  data = gamingBiweekly)\nmodelsummary(\n  list(`Model h2c` = model.h2c),\n  fmt = 2,\n  estimate  = \"{estimate} [{conf.low}, {conf.high}]{stars}\", \n  statistic = NULL\n)\n\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                Model h2c\n              \n        \n        \n        \n                \n                  (Intercept)                                 \n                  3.01 [2.95, 3.06]***\n                \n                \n                  biweekly_avg_minutes_played                 \n                  0.00 [-0.03, 0.03]  \n                \n                \n                  msf_sc_numeric                              \n                  0.00 [-0.01, 0.00]  \n                \n                \n                  age_scaled                                  \n                  0.00 [-0.03, 0.03]  \n                \n                \n                  bmi_scaled                                  \n                  0.02 [-0.01, 0.04]  \n                \n                \n                  SES_index_scaled                            \n                  0.02 [-0.01, 0.04]  \n                \n                \n                  regionUS                                    \n                  0.02 [-0.04, 0.08]  \n                \n                \n                  isWeekend                                   \n                  0.00 [-0.03, 0.02]  \n                \n                \n                  biweekly_avg_minutes_played × msf_sc_numeric\n                  0.00 [0.00, 0.00]   \n                \n                \n                  SD (Intercept pid)                          \n                  0.21                \n                \n                \n                  SD (Intercept gender)                       \n                  0.00                \n                \n                \n                  SD (Observations)                           \n                  0.50                \n                \n                \n                  Num.Obs.                                    \n                  5388                \n                \n                \n                  R2 Marg.                                    \n                  0.003               \n                \n                \n                  AIC                                         \n                  8541.2              \n                \n                \n                  BIC                                         \n                  8620.3              \n                \n                \n                  RMSE                                        \n                  0.48                \n                \n        \n      \n    \n\n\n\n\n\n5.6.2 H2d: The negative association between late-night gaming and daytime sleepiness is more pronounced among evening chronotypes.\nMultilevel linear regression whereby the interaction between biweekly average minutes played and chronotype (MSFsc; MCTQ) predicts well-being (WEMWBS), controlling for age, BMI, SES index, region, gender, and whether playtime falls on a weekend, with a random intercept for participants and a random intercept for gender.\n\n\nFit H2d model\nmodel.h2d &lt;- lmer(epsTotal ~ monthly_avg_minutes_played * msf_sc_numeric + (1 + monthly_avg_minutes_played | pid) +\n                    age_scaled + bmi_scaled + SES_index_scaled + region + isWeekend + (1 | gender), \n                  data = gamingMonthly)\n                  \nmodelsummary(\n  list(`Model H2d` = model.h2d),\n  fmt = 2,\n  estimate  = \"{estimate} [{conf.low}, {conf.high}]{stars}\", \n  statistic = NULL\n)\n\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                Model H2d\n              \n        \n        \n        \n                \n                  (Intercept)                                   \n                  7.45 [6.64, 8.25]***\n                \n                \n                  monthly_avg_minutes_played                    \n                  0.76 [-1.25, 2.77]  \n                \n                \n                  msf_sc_numeric                                \n                  -0.02 [-0.07, 0.03] \n                \n                \n                  age_scaled                                    \n                  -0.03 [-0.49, 0.43] \n                \n                \n                  bmi_scaled                                    \n                  0.05 [-0.28, 0.38]  \n                \n                \n                  SES_index_scaled                              \n                  -0.03 [-0.36, 0.30] \n                \n                \n                  regionUS                                      \n                  0.16 [-0.75, 1.06]  \n                \n                \n                  isWeekend                                     \n                  0.01 [-0.28, 0.30]  \n                \n                \n                  monthly_avg_minutes_played × msf_sc_numeric   \n                  -0.04 [-0.14, 0.07] \n                \n                \n                  SD (Intercept pid)                            \n                  4.15                \n                \n                \n                  SD (monthly_avg_minutes_played pid)           \n                  0.27                \n                \n                \n                  Cor (Intercept~monthly_avg_minutes_played pid)\n                  1.00                \n                \n                \n                  SD (Intercept gender)                         \n                  0.00                \n                \n                \n                  SD (Observations)                             \n                  4.89                \n                \n                \n                  Num.Obs.                                      \n                  4408                \n                \n                \n                  R2 Marg.                                      \n                  0.001               \n                \n                \n                  AIC                                           \n                  27791.8             \n                \n                \n                  BIC                                           \n                  27881.2             \n                \n                \n                  RMSE                                          \n                  4.53",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Study 2: Gaming and Sleep</span>"
    ]
  }
]